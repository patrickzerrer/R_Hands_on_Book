---
title: "Die Varianzanalyse"
author: "Katharina Maubach"
toc: true
number-sections: true
highlight-style: pygments
format:
  html:
    code-fold: false
    code-line-numbers: true
---

## Die Varianzanalyse

Die Varianzanalyse weitet den Grundgedanken des t-Tests aus, indem sie den simultanen Vergleich von Gruppenmittelwerten √ºber mehr als zwei Gruppen erlaubt. Die einfaktorielle Varianzanalyse definiert die Gruppen dabei anhand eines Faktors (einer unabh√§ngigen Variable), die mehrfaktorielle Varianzanalyse erlaubt mehrere unabh√§ngige kategoriale Variablen im Modell, ist aber nicht mit der multivariaten Varianzanalyse (MANOVA) zu verwechseln, die auch mehrere metrische abh√§ngige Variablen gleichzeitig zul√§sst. Wenn die Gruppierungsvariable (also die unabh√§ngige Faktor-Variable) mehr als zwei Gruppen unterscheidet, m√ºssen nach der Anova Post-Hoc Tests durchgef√ºhrt werden. Denn sollte die Varianzanalyse insgesamt signifikante Werte liefern, wurde zwar festgestellt, dass es √ºberzuf√§llige Unterschiede zwischen den durch die Faktorstufen definierten Gruppen gibt, bei drei und mehr Faktorstufen bleibt aber noch unklar, auf welchen Gruppenunterschieden dieses Ergebnis beruht. Post hoc-Tests liefern spezifischere Informationen dazu, welche Gruppenmittelwerte signifikant voneinander abweichen.

### Datenmanagement

In R ist es zwingend notwendig, neben dem Programm als solches auch die Daten zu laden. Nachfolgend findet sich der `load`-Befehl. Dieser l√§dt die R-Daten. Daf√ºr ist es wichtig, das diese im selben Ordner wie dieses Skript gespeichert sind. Zudem m√ºssen wir die Pakete laden. Hier nutzen wir den Paketmanagaer pacman. Diese muss einmal installiert und geladen werden und anschlie√üend k√∂nnen mit dem Befehl p_load alle ben√∂tigten Pakete gleichzeitig installiert und geladen werden.

```{r}
#Pakete laden
if(!require("pacman")) {install.packages("pacman");library(pacman)}
<<<<<<< HEAD
p_load(knitr,car, tidyverse, ggplot2, DescTools, dplyr,afex, emmeans, PMCMRplus)

#Daten laden
daten <- read_rds("Datensatz/ESS8_vier_laender.rds")

#Visualisierungshintergrund festlegen
theme_set(theme_minimal())
```

## Voraussetzungspr√ºfung f√ºr einfaktorielle und mehrfaktorielle Varianzanalyse
=======
p_load(knitr,car, tidyverse, ggplot2, DescTools, dplyr,afex, emmeans, PMCMRplus, sjmisc)
```

Anschlie√üend laden wir unseren Datensatz:

```{r}
daten = haven::read_dta("Datensatz/Allbus_2021.dta")
theme_set(theme_classic())
```

## Datenmanagement

Um mit dem Datensatz zu arbeiten ben√∂tigen wir einige grundlegende Schritte des Datenmanagements [f√ºr ausf√ºhrliche Erkl√§rungen siehe hier](https://patrickzerrer.github.io/R_Hands_on_Book/Skript_3.3.html). F√ºr unsere Varianzanalyse m√∂chten wir uns anschauen, wie sich der Gesundheitszustand (und das Alter) der Befragten auf ihr Vertrauen in das Gesundheitswesen auswirkt. Wir nutzen dazu die folgenden Variablen:

+---------------+-----------------------------------+-------------------------+
| Variable      | Beschreibung                      | Auspr√§gungen            |
+:=============:+:=================================:+:=======================:+
| hs01          | Gesundheitszustand der Befragten  | -42 = Datenfehler       |
|               |                                   |                         |
|               |                                   | -11 = TNZ Split         |
|               |                                   |                         |
|               |                                   | -9 = Keine Angabe       |
|               |                                   |                         |
|               |                                   | 1 = Sehr Gut            |
|               |                                   |                         |
|               |                                   | 2 = Gut                 |
|               |                                   |                         |
|               |                                   | 3 = Zufriedenstellend   |
|               |                                   |                         |
|               |                                   | 4 = Weniger Gut         |
|               |                                   |                         |
|               |                                   | 5 = Schlecht            |
+---------------+-----------------------------------+-------------------------+
| age           | Alter der Befragten               | -32 = Nicht Generierbar |
+---------------+-----------------------------------+-------------------------+
| pt01          | Vertrauen in das Gesundheitswesen | -42 = Datenfehler       |
|               |                                   |                         |
|               |                                   | -11 = TNZ Split         |
|               |                                   |                         |
|               |                                   | -9 = Keine Angabe       |
|               |                                   |                         |
|               |                                   | 1 = Gar kein Vertrauen  |
|               |                                   |                         |
|               |                                   | ...                     |
|               |                                   |                         |
|               |                                   | 7 = Gro√ües Vertrauen    |
+---------------+-----------------------------------+-------------------------+

Innerhalb unseres Datenmanagements schlie√üen wir fehlerhafte und fehlende Werte der Variablen sex, agef und pt12 aus und benennen falls n√∂tig die Variablen um:

```{r}

daten <- daten %>%
  filter(., hs01 > 0 & pt01 > 0 & age > 0) %>% 
  rename(., gesund = hs01,
            trustges = pt01) %>% 
  mutate(gesund = haven::as_factor(gesund),
         trustges = as.numeric(trustges),
         agef = dicho(age, as.num = T) %>% factor(levels = c(0,1), labels = c("jung", "alt")))

```


# Voraussetzungspr√ºfung f√ºr einfaktorielle und mehrfaktorielle Varianzanalyse
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc

Die Varianzanalyse ist ein statistisches Verfahren, dass bestimmte Voraussetzungen bez√ºglich der abh√§ngigen und unabh√§ngigen Variablen voraussetzt. Dies sind im √úberblick:

-   Datenniveau der AV (metrisch) und UV (Faktor)
-   Normalverteilung der abh√§ngiven Variablen
-   Homogenit√§t der Fehlervarianzen der unabh√§ngigen Variablen

Die meisten Voraussetzungen, die f√ºr die Durchf√ºhrung und Interpretation einer Varianzanalyse erf√ºllt sein m√ºssen, lassen sich bereits im Vorfeld der eigentlichen Analyse √ºberpr√ºfen. So kann das Messniveau unmitttelbar festgestellt werden. Es gilt f√ºr die **abh√§ngige (y-)Variable** stets, dass sie **intervallskaliert** sein muss, in R also als ein Vektor vorliegen muss. Die Faktoren bzw. **unabh√§ngige(n) (x-) Variable(n)** hingegen m√ºssen zwingend nominalskaliert sein und in R demnach als **Faktoren** vorliegen.

### √úberpr√ºfung der Normalverteilung

Eine weitere wichtige, leicht vorab zu pr√ºfende Bedingung, die f√ºr eine Varianzanalyse erf√ºllt sein muss, ist die **Normalverteilung der abh√§ngigen Variable**. Diese k√∂nnen wir graphisch √ºberpr√ºfen:

In R nutzen wir das Paket `ggplot2` von Wickham et al. um ein Histogramm auszugeben. Zun√§chst m√ºssen wir hier das Paket `ggplot2` mit dem Befehl `ggplot()` aufrufen. Anschlie√üend spezifizieren wir innerhalb der Klammer unseren Datensatz (hier `Varianzanalyse`) und unter aes unsere Variable (hier `Angst`). Mit einem Plus-Zeichen legen wir die n√§chste Ebene fest und geben hier mit `geom_histogram` an, dass wir ein Histogramm w√ºnschen. Die Spezifizierungen innerhalb der Klammer geben an, dass dieses auf den Zahlen unseres Datensatzes beruhen soll `(aes(y = ..count..))`, wir die Au√üenumrandung schwarz `color = black` und die F√ºllfarbe grau w√ºnschen (`fill = grey`). Diese Spezifikationen sind optional, sorgen jedoch f√ºr ein sch√∂neres Aussehen unserer Grafik. Zuletzt legen wir innerhalb der Klammer die Breite unserer S√§ulen fest. Mit `binwidth = 1` verweisen wir hier auf eine Breite der Balken 1. Nun haben wir ein vollst√§ndiges Histogramm. Wir k√∂nnen jedoch f√ºr ein versch√∂nertes Aussehen unseres Graphen mit `labs` zus√§tzlich die Achsen beschriften.

```{r}
#Histogramm ausgeben
ggplot(daten, aes(happy)) +
  geom_histogram(aes(y = ..count..), 
                 color = "black", fill = "grey", 
                 binwidth = 1) +
  labs(x = "Zufriedenheit", 
         y = "")
```

<<<<<<< HEAD
Wir sehen an der Grafik, dass die Variable Zufriedenheit rechtssteil ist, also die Teilnehmer der Befragung eher eine h√∂here Zufriedenheit angegeben haben.
=======
Wir sehen an der Grafik, dass die Variable Vertrauen in das Gesundheitswesen rechtssteil ist, also die Teilnehmer der Befragung eher ein h√∂heres Vertrauen angegeben haben.
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc

Zus√§tzliche Gewissheit beu√ºglich des Vorliegens der Normalverteilung bietet der Kolmogorov-Smirnov-Test oder der Shapiro-Wilk-Test (bei diesem wird jedoch eine Stichprobengr√∂√üe zwischen 3 und 5000 vorausgesetzt, welche wir hier √ºberschreiten, daher rechnen wir nur den Kolmogorov-Smirnov-Test). In R erhalten wir diese Tests mit dem Befehl `LillieTest()` aus dem Paket `DescTools()` bzw. `shapiro.test()`. Beide Tests testen auf Abweichung von der Normalverteilung, demnach sollte diese nicht signifikant ausfallen (da ein signifikanter Test aussagt, dass eine Abweichung von der Normalverteilung besteht, was wir nicht m√∂chten).

```{r}
#Lilliefors Kolmogorov-Smirnov-Test
LillieTest(daten$happy)
#Shapiro-Wilk Test
#shapiro.test(daten$happy)
```

Im vorliegenden Beispiel ist der Test signifikant. Allerdings reagieren beide Tests insbesondere bei gro√üen Stichproben sehr sensibel, sodass bereits leichte Abweichungen von der Normalverteilung (etwa durch Ausrei√üer) die Tests signifikant werden lassen; in diesen F√§llen ist es sinnvoll eher auf die graphische √úberpr√ºfung (siehe oben) zu schauen. Sowohl der Kolmogorov-Smirnov-Test als auch die Grafik lassen jedoch nicht auf eine perfekte Normalverteilung unserer abh√§ngigen Variablen schlie√üen. In diesem Fall kann die Varianzanalyse dennoch gerechnet werden, da solange die Verteilung nicht extrem steil ist, das Verfahren einigerma√üen robust ist. Bei einer sehr starken Verletzung der Normalverteilung m√ºsste ggf. auf nicht parametrische Tests ausgewichen werden.

## √úberpr√ºfung der Homogenit√§t der Fehlervarianzen

Die letzte Voraussetzung, die f√ºr eine Varianzanalyse erf√ºllt sein muss, ist die Homogenit√§t der Fehlervarianzen. Um diese zu testen, nutzen wir den Levene-Test auf Varianzhomogenit√§t. Hierf√ºr nutzen wir die Funktion `leveneTest()`aus dem Paket `car`. Innerhalb der Klammer m√ºssen wir zun√§chst unsere abh√§ngige Variable angeben. Danach folgt eine Tilde (\~). Im Anschluss m√ºssen wir unsere unabh√§ngige(n) Variablen angeben. Die Tilde sagt quasi, dass unsere abh√§ngige Variable durch unsere unabh√§ngigen Variablen bestimmt wird. Haben wir nur eine abh√§ngige Variable, so geben wir diese an. Haben wir mehrere so k√∂nnen wir diese mit einem \* verbinden. Hier wird der Test f√ºr beide Variablen sowie den Interaktionsterm ausgeben.

```{r}
#Levene-Test f√ºr einfaktorielle Varianzanalyse
daten %>% 
  leveneTest(happy~cntry, data = ., center = mean)

#Levene-Test f√ºr mehrfaktorielle Varianzanalyse ausgeben
daten %>% 
<<<<<<< HEAD
  leveneTest(happy ~ cntry*gndr, data = ., center = mean)
=======
  leveneTest(trustges ~ gesund*agef, data = ., center = mean) #<2>
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc
```

Wenn der Levene-Test statistisch signifikant ausf√§llt, sollte die Hypothese homogener Varianzen abgelehnt werden. Falls der Test wie im vorliegenden Fall signifikant ausf√§llt (da der `Pr(>F-Wert)` kleiner als 0.05 ist) wurde die Voraussetzung der Homogenit√§t der Fehlervarianzen verletzt. In einem solchen Fall k√∂nnen wir wahlweise auf nicht-parametrische Tests ausweichen, oder die Varianzanalyse dennoch berechnen, wenn wahlweise die deskriptiven Kennwerte keine allzu gro√üe Streuung aufweisen, oder wir einen alternativen Posthoc-Test (etwa Tamhame T2) w√§hlen.

## Einfaktorielle Varianzanalyse (ohne Messwiederholung)

Nachdem wir die Voraussetzungen gepr√ºft haben, schauen wir uns die einfaktorielle Varianzanalyse an. Im vorliegenden Beispiel m√∂chten wir gerne √ºberpr√ºfen, inwiefern sich die Nationalit√§t bzw. L√§nderzugeh√∂rigkeit (Variable `cntry`; Deutschland, Schweden, Frankreich und Gro√übritannien) auf die Lebenszufriedenheit (Variable `happy`) auswirkt.

<<<<<<< HEAD
Zun√§chst m√∂chten wir uns anhand von deskriptiven Statistiken einen √úberblick √ºber unsere Daten verschaffen. Daf√ºr nutzen wir die `group_by`-Funktion in Kombination mit der `summarise`-Funktion. Im nachfolgenden Schritt haben wir mit Hilfe des Befehls `kable()` aus dem Paket `knitr` das Aussehen unserer Tabelle versch√∂nert. Dieser Schritt ist optional.

```{r}
daten %>% 
  group_by(cntry) %>% 
  summarise(Mittelwert = mean(happy, na.rm = T), 
            Standardabweichung = sd(happy, na.rm = T)) %>% 
  kable(digits = 2, col.names = c("Land", "M", "SD"), caption = "Descriptives Lebenszufriedenheit")
```

Anhand der deskriptiven Statistiken sehen wir, dass die Zufriedenheit in Frankreich am geringsten ist und in Schweden am h√∂chsten. Zudem erkennen wir, dass die Standardabweichungen der L√§ndern sich nicht drastisch unterscheiden, wir demnach trotz der Verletzung der Varianzhomogenit√§t die ANOVA rechnen k√∂nnen.

Anschlie√üend k√∂nnen wir die einfaktorielle ANOVA berechnen.Daf√ºr nutzen wir die Funktion `aov_car` aus dem `afex`-Package, in welcher wir zun√§chst die abh√§ngige Variable (`happy`) angeben m√ºssen und nach einer Tilde die unabh√§ngige Variabel (`cntry`) Zudem m√ºssen wir den Zusatz `+ Error()` nutzen un in der Klammer die Fallid (hier `idno`) angeben. Da die Variable idno doppelte F√§lle hatte m√ºssen wir in dem vorliegenden Beispiel diese ausschlie√üen, da andernfalls der Befehl nicht funktioniert. Dies geschieht mit dem Befehl `distinct` welcher aus der Variablen `idno` alle doppelten F√§lle ausschlie√üt. Der Zusatz `.keep_all = T` bedeutet, dass wir alle Variablen des Datensatzes behalten wollen und nur die doppelten F√§lle ausgeschlossen werden sollen. Alles speichern wir als Objekt `fit` welches wir anschlie√üend mit `print` aufrufen.
=======
Nachdem wir die Voraussetzungen gepr√ºft haben, schauen wir uns die einfaktorielle Varianzanalyse an. Im vorliegenden Beispiel m√∂chten wir gerne √ºberpr√ºfen, inwiefern sich das Alter (Variable `agef`; ) auf das Vertrauen in die Bundesregierung (Variable `trustreg`) auswirkt.

```{r}

daten %>% 
  group_by(gesund) %>% 
  summarise(Mittelwert = mean(trustges, na.rm = T), 
            Standardabweichung = sd(trustges, na.rm = T)) %>% 
  kable(digits = 2, col.names = c("Gesundheitszustand", "M", "SD"), caption = "Descriptives Vertrauen")
```

Anhand der deskriptiven Statistiken sehen wir, dass das Vertrauen in das Gesundheitswesen am h√∂chsten ausgepr√§gt ist, bei Personen die einen guten Gesundheitszustand aufweisen. Ob dieser augenscheinliche Unterschied auch statistisch signifikant ist, m√∂chten wir in einem n√§chsten Schritt mit der einfaktoriellen ANOVA berechnen. Daf√ºr nutzen wir die Funktion `aov_car` aus dem `afex`-Packag:
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc

```{r}
#Einfaktorielle ANOVA
fit <- daten %>% 
<<<<<<< HEAD
dplyr::distinct(idno, .keep_all = T) %>% 
aov_car(happy ~ cntry + Error(idno), data = ., anova_table = "pes")
=======
aov_car(trustges ~ gesund + Error(respid), data = ., anova_table = "pes")
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc

print(fit)
```

<<<<<<< HEAD
=======
in welcher wir zun√§chst die abh√§ngige Variable (`happy`) angeben m√ºssen und nach einer Tilde die unabh√§ngige Variabel (`cntry`) Zudem m√ºssen wir den Zusatz `+ Error()` nutzen un in der Klammer die Fallid (hier `idno`) angeben. 

Alles speichern wir als Objekt `fit` welches wir anschlie√üend mit `print` aufrufen.

## Interpretation des Outputs

>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc
Als Output erhalten wir eine Tabelle mit den folgenden Parametern:

-   Effect: unabh√§ngige Variable
-   df: Freiheitsgrade (degrees of freedom)
-   MSE: Fehlervarianz, mittlere quadratische Abweichung (mean squared errors)
-   F: F-Werte
-   pes: parties Eta-Quadrat (partial eta-quared)
-   p.value: Signifikanz

<<<<<<< HEAD
**Effect** zeigt die unabh√§ngige Variable des Modells, in diesem Fall die L√§ndervariable `cntry`. Die drei bedeutet, dass hier insgesamt eine Gruppe mit 3 anderen (= vier Auspr√§gungen) verglichen wurde. mean-squared errors

√úber die Werte der zweiten und vierten Spalte, die **Freiheitsgrade** (`df`) und die **F-Werte** (`F`) lie√üe sich, wenn man es wollte, der emprische F-Wert in der F-Tabelle, mit dem kritischen Wert (theoretischen F-Wert) vergleichen, um zu pr√ºfen, ob die Nullhypothese, dass keine Unterschiede zwischen den durch die jeweilige Variable definierten Gruppen bestehen, verworfen werden darf. Diesen Aufwand kann man sich allerdings sparen, da R in der Spalte `p.value` die umgekehrte Aussage macht, dass die Nullhypothese mit der dort berichteten Fehlerwahrscheinlichkeit verworfen werden kann. Beim per Konvention in den Sozialwissenschaften mindestens geltenden Konfidenz-Niveau von 95%, d√ºrfen im Umkehrschluss also f√ºr alle Modellterme signifikante Unterschiede in der Grundgesamtheit angenommen werden, die hier einen Wert \<.05 aufweisen. Die Spalte ist damit die wichtigste der gesamten Tabelle! Im vorliegenden Datenbeispiel ist demnach ein signifikanter Unterschied der L√§nder im Bezug auf die Lebenszufriedenheit ersichtlich.

Die mittlere quadratische Abweichung (MSE) oder Fehlervarianz ist die Summe der Abweichungsquadrate aller Werte vom jeweiligen Gruppenmittelwert. Berechnet wird diese durch die Quadratsummer der Fehlerresiduen geteilt durch die Freiheitsgrade. Sie gibt damit die Varianz innerhalb der einzelnen Gruppen (=nicht erkl√§rte Varianz) wieder.

Die Spalte `pes` steht f√ºr das partielle Eta-Quadrat und gibt die Erkl√§rungskraft der einzelnen Faktoren im Hinblick auf die anh√§ngige Variable an -- partiell ist das Eta^2^, da es um die Einfl√ºsse der √ºbrigen Modellgr√∂√üen bereinigt ist (f√ºr unifaktorielle Analysen wie im vorliegenden Fall ist dies nicht relevant, allerdings f√ºr die multifaktorielle ANOVA). Im Datenbeispiel hat demnach die L√§nderzugeh√∂rigkeit (und damit auch unser Gesamtmodell) eine Erkl√§rkraft von 1.8 Prozent. Allerdings wissen wir lediglich, dass sich unsere Gruppen signifikant unterscheiden, nicht jedoch, ob sich alle Gruppen unterscheiden, oder lediglich einzelne. Daher ben√∂tigen wir die Posthoc-Tests.
=======
**Effect** zeigt die unabh√§ngige Variable des Modells, in diesem Fall die Variable Gesundheitszustand(`gesund`). Die vier bedeutet, dass hier insgesamt eine Gruppe mit 4 anderen (= f√ºnf Auspr√§gungen) verglichen wurde.

√úber die Werte der zweiten und vierten Spalte, die **Freiheitsgrade** (`df`) und die **F-Werte** (`F`) lie√üe sich, wenn man es wollte, der emprische F-Wert in der F-Tabelle, mit dem kritischen Wert (theoretischen F-Wert) vergleichen, um zu pr√ºfen, ob die Nullhypothese, dass keine Unterschiede zwischen den durch die jeweilige Variable definierten Gruppen bestehen, verworfen werden darf. Diesen Aufwand kann man sich allerdings sparen, da R in der Spalte `p.value` die umgekehrte Aussage macht, dass die Nullhypothese mit der dort berichteten Fehlerwahrscheinlichkeit verworfen werden kann. Beim per Konvention in den Sozialwissenschaften mindestens geltenden Konfidenz-Niveau von 95%, d√ºrfen im Umkehrschluss also f√ºr alle Modellterme signifikante Unterschiede in der Grundgesamtheit angenommen werden, die hier einen Wert \<.05 aufweisen. Die Spalte ist damit die wichtigste der gesamten Tabelle! Im vorliegenden Datenbeispiel ist demnach ein signifikanter Unterschied des Gesundheitszustandes im Bezug auf das Vertrauen in das Gesundheitswesen ersichtlich.

Die mittlere quadratische Abweichung (MSE) oder Fehlervarianz ist die Summe der Abweichungsquadrate aller Werte vom jeweiligen Gruppenmittelwert. Berechnet wird diese durch die Quadratsummer der Fehlerresiduen geteilt durch die Freiheitsgrade. Sie gibt damit die Varianz innerhalb der einzelnen Gruppen (=nicht erkl√§rte Varianz) wieder.

Die Spalte `pes` steht f√ºr das partielle Eta-Quadrat und gibt die Erkl√§rungskraft der einzelnen Faktoren im Hinblick auf die anh√§ngige Variable an -- partiell ist das Eta^2^, da es um die Einfl√ºsse der √ºbrigen Modellgr√∂√üen bereinigt ist (f√ºr unifaktorielle Analysen wie im vorliegenden Fall ist dies nicht relevant, allerdings f√ºr die multifaktorielle ANOVA). Im Datenbeispiel hat demnach der Gesundheitszustand (und damit auch unser Gesamtmodell) eine Erkl√§rkraft von 0.6 Prozent f√ºr Unterschiede im Vertrauen auf das Gesundheitssystem. Allerdings wissen wir lediglich, dass sich unsere Gruppen signifikant unterscheiden, nicht jedoch, ob sich alle Gruppen unterscheiden, oder lediglich einzelne. Daher ben√∂tigen wir die Posthoc-Tests.
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc

## PostHocTests

Zuletzt m√ºssen wir die Posthoc-Tests berechnen, welche uns Aufschluss dar√ºber geben, welche unserer Gruppen sich unterscheiden. Es gibt verschiedene Posthoc-Tests. Grunds√§tzlich ist der Tukex-Post-Hoc Test zu empfehlen, welche wir √ºber die Funktion `emmeans`aus dem `emmeans`-Package aufrufen. Bei fehlender Varianzhomogenit√§t k√∂nnen wir zudem den tamhane-T2 Test nutzen. Dieser basiert allerdings auf einem aov-Objekt, daher geben wir hier mit aov die ANOVA erneut aus. Innerhalb von emmeans k√∂nnen wir hingegen einfach auf unser zuvor spezifiziertes Modell fit verweisen, m√ºssen allerdings noch mit specs= angeben, auf Basis welcher Variablen der Gruppenvergleich durchgef√ºhrt werden soll.

```{r}
#Tukey Post-Hoc Test
emmeans::emmeans(fit, specs = "cntry") %>% 
  pairs()

#Tamhame T2 Test
daten %>% 
aov(happy ~ cntry, data = .) %>% 
  tamhaneT2Test(.)
```
## Interpretation der Posthoc-Tests und des Gesamtmodells

Hier interessiert uns jeweils der p-value (f√ºr den Tamhame T2 Test wird uns nur dieser angezeigt). Werte unter .05 bedeuten, dass zwischen diesen Gruppen ein signifikanter Mittelwertunterschied besteht. In unserem Beispiel sehen wir Unterschiede zwischen Frankreich und allen weiteren L√§ndern, sowie einen Unterschied zwischen Gro√übritannien und Schweden. Wenn wir auf die deskriptiven Statistiken schauen, sehen wir demnach, dass in Frankreich die Lebenszufriedenheit signifikant geringer als in Deutschland, Schweden und Gro√übritannien ist, sowie die Lebenszufriedenheit in Gro√übritannien signifikant geringer als in Schweden ausf√§llt.

SEHR GUT - ZUFRIEDENSTELLEND      0.2749 0.0734 3470   3.746  0.0017
 SEHR GUT - WENIGER GUT            0.3077 0.0924 3470   3.332  0.0078
 SEHR GUT - SCHLECHT               0.4123 0.1474 3470   2.797  0.0414
 GUT - ZUFRIEDENSTELLEND  


Sehr Gut und Zufriedenstellend /Schlecht

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse der Varianzanalyse werden zumeist in XX dargestellt. Daf√ºr werden folgende Informationen ben√∂tigt:

‚úÖ 

‚úÖ 


Das Format ist √ºblicherweise:

> ***Beispiel:*** Work in Progress

:::

## Exkurs: Kruskal Wallis Test

## Mehrfaktorielle Varianzanalyse

In der mehrfaktoriellen Varianzanalyse k√∂nnen wir unser Modell aus der einfachen Varianzananlyse erweitern. In diesem Beispiel nutzen wir neben der Variablen zum Gesundheitszustand (`gesund`) zus√§tzlich die Variable Alter (`agef`) um das Vertrauen in das Gesundheitssystem (`trustges`) vorherzusagen.

Zun√§chst m√∂chten wir uns anhand von deskriptiven Statistiken einen √úberblick √ºber unsere Daten verschaffen. 

```{r}
#Deskriptive Statistiken ausgeben
daten %>% 
<<<<<<< HEAD
  group_by(cntry, gndr) %>% 
  summarise(Mittelwert = mean(happy, na.rm = T), 
            Standardabweichung = SD(happy, na.rm = T)) %>% 
  kable(digits = 2, col.names = c("Land", "Geschlecht", "M", "SD"), caption = "Descriptives Lebenszufriedenheit")
=======
  group_by(gesund, agef) %>% 
  summarise(Mittelwert = mean(trustges, na.rm = T), 
            Standardabweichung = SD(trustges, na.rm = T)) %>% 
  kable(digits = 2, col.names = c("Gesundheitszustand", "Alter", "M", "SD"), caption = "Descriptives Vertrauen")
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc
```
Daf√ºr nutzen wir die `group_by`-Funktion in Kombination mit der `summarise`-Funktion. Im nachfolgenden Schritt haben wir mit Hilfe des Befehls `kable()` aus dem Paket `knitr` das Aussehen unserer Tabelle versch√∂nert. Dieser Schritt ist optional.

Zun√§chst k√∂nnen wir unsere deskriptiven Statistiken betrachten. Hier interessieren uns insbesondere die Mittelwerte f√ºr die einzelnen Gruppen. Diese Mittelwerte im Flie√ütext kurz zu erw√§hnen, geh√∂rt zum ‚Äûguten Ton" bei der Auswertung einer Varianzanalyse und sollte daher nicht vergessen werden.

Nun k√∂nnen wir unsere ANOVA aufstellen. Es gibt verschiedene M√∂glichkeiten eine ANOVA zu berechnen, namentlich Type I, II und III. Die einzelnen Typen unterscheiden sich darin, wie die Parameter (insbesondere die Quadratsumme) berechnet wird. Typ I sollte vor allem f√ºr ausgeglichene Daten verwendet werden, also Daten bei der f√ºr jede Gruppe die gleiche Anzahl an F√§llen vorliegen. Ist dies nicht der Fall, sollte Typ II oder Typ III (beispielsweise die Option der Anova in SPSS) verwendet werden. Der typische Befehl f√ºr eine Anova in R ist der Befehl `aov()`. Dieser ist jedoch nur f√ºr die Typ I Anova ausgelegt, daher nutzen wir hier erneut den Befehl `aov_car()` (sowie den distict-Befehl) aus dem `afex`-Paket welcher standardm√§√üig die Anova nach Typ III berechnet. Im Prinzip nutzen wir die selbe Syntax wie bei der unifaktoriellen Anova. Wir erg√§nzen allerdings unsere zweitere unabh√§ngige Variable, beziehungsweise verbinden die beiden unabh√§ngigen Variablen mit einem \*. Dadurch erhalten wir sowohl die Werte f√ºr die einzelnen Variablen als auch f√ºr den Interaktionsterm, also das Zusammenspiel der Variablen.

```{r}
fit2 <- daten %>% 
<<<<<<< HEAD
dplyr::distinct(idno, .keep_all = TRUE) %>% 
  afex::aov_car(happy ~ cntry * gndr + Error(idno),
=======
  afex::aov_car(trustges ~ gesund * agef + Error(respid),
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc
                                     data = ., anova_table = "pes")
print(fit2)
```
## Interpretation des Outputs

Die Erl√§uterungen der einzelnen Parameter sind gleich zu den Erl√§uterungen der unifaktoriellen ANOVA, daher werden diese nicht wiederholt. Es zeigt sich, dass der Gesundheitszustand erneut einen signifikanten Einfluss auf das Vertrauen in das Gesundheitswesen hat (welcher im vorliegenden Modell etwas h√∂her mit 0.9 Prozent erkl√§rter Varianz ausf√§llt). Zus√§tzlich hat neben der Gesundheitszustand auch das Alter der Befragten einen signifikanten, wenngleich geringeren Einfluss auf das Vertrauen in das Gesundheitswesen. Zudem sehen wir einen signifikanten Einfluss der Interaktion von Alter und Gesundheitszustand (`gesund:agef4`). 

Im Anschluss m√ºssen wir, wie in der univariaten ANOVA, die Posthoc-Tests berechnen (im vorliegenden Fall k√∂nnen wir lediglich den Tukey-Test berechnen, das der Tamhame-Test nur f√ºr einfaktorielle Designs funktioniert).

### Post-Hoc Tests

```{r}
#Tukey Post-Hoc Test
<<<<<<< HEAD
emmeans::emmeans(fit2, specs = c("cntry", "gndr")) %>% 
=======
emmeans::emmeans(fit2, specs = c("gesund", "agef")) %>% 
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc
  pairs()
```

### Interaktionen visualisieren

Um einen m√∂glichen Interaktionseffekt auch anschaulich vermitteln bzw. oft auch verstehen zu k√∂nnen, empfiehlt es sich, diesen als Diagramm darzustellen. Hierzu nutzen wir die Pakete `emmeans` und `ggplot2`.

```{r}
#Interaktionsplot ausgeben
<<<<<<< HEAD
emmip(fit2, cntry ~ gndr) + 
  labs(title = "Gesch√§tzes Randmittel von Lebenszufriedenheit", 
       y = "Gesch√§tzte Randmittel",
       x = "Geschlecht")

emmip(fit2, gndr ~ cntry) + 
  labs(title = "Gesch√§tzes Randmittel von Lebenszufriedenheit", 
       y = "Gesch√§tzte Randmittel",
       x = "Land")
=======
emmip(fit2, agef ~ gesund) + 
  labs(title = "Gesch√§tzes Randmittel von Vertrauen in das Gesundheitswesen", 
       y = "Gesch√§tzte Randmittel",
       x = "Alter der Befragten")

emmip(fit2, gesund ~ agef) + 
  labs(title = "Gesch√§tzes Randmittel von Vertrauen in das Gesundheitswesen", 
       y = "Gesch√§tzte Randmittel",
       x = "Gesundheitszustand")
>>>>>>> 310757c20b6e67efcb3cca68a7dc8427760383bc
```
## Interpretation der Posthoc-Tests und des Gesamtmodells


## Literatur

::: callout-note
## Literatur und Beispiele aus der Praxis

Wir empfehlen euch folgende Lehrb√ºcher, falls ihr weiterf√ºhrende Informationen braucht.

> üìñ Field, Z., Miles, J., & Field, A. (2012). Discovering statistics using R. Discovering statistics using r, 1-992. [Link](https://suche.suub.uni-bremen.de/peid=B68436977&LAN=DE&CID=7699632&index=L&Hitnr=1&dtyp=D&rtyp=a&Exemplar=1)


Hier findet ihr ein Beispiel aus der Forschungspraxis:

> üî¨ wird noch erg√§nzt.
:::

