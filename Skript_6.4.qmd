---
title: "Die Varianzanalyse"
author: "Katharina Maubach"
toc: true
number-sections: true
highlight-style: pygments
execute: 
  warning: false
  message: false
format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
---

![Bild generiert von Midjourney](Bilder/Bild_Varianzanalyse.png)

Die Varianzanalyse weitet den Grundgedanken des t-Tests aus, indem sie den simultanen Vergleich von Gruppenmittelwerten √ºber mehr als zwei Gruppen erlaubt. Die einfaktorielle Varianzanalyse definiert die Gruppen dabei anhand eines Faktors (einer unabh√§ngigen Variable), die mehrfaktorielle Varianzanalyse erlaubt mehrere unabh√§ngige kategoriale Variablen im Modell, ist aber nicht mit der multivariaten Varianzanalyse (MANOVA) zu verwechseln, die auch mehrere metrische abh√§ngige Variablen gleichzeitig zul√§sst. Wenn die Gruppierungsvariable (also die unabh√§ngige Faktor-Variable) mehr als zwei Gruppen unterscheidet, m√ºssen nach der Anova Post-Hoc Tests durchgef√ºhrt werden. Denn sollte die Varianzanalyse insgesamt signifikante Werte liefern, wurde zwar festgestellt, dass es √ºberzuf√§llige Unterschiede zwischen den durch die Faktorstufen definierten Gruppen gibt, bei drei und mehr Faktorstufen bleibt aber noch unklar, auf welchen Gruppenunterschieden dieses Ergebnis beruht. Post hoc-Tests liefern spezifischere Informationen dazu, welche Gruppenmittelwerte signifikant voneinander abweichen.

# Datenmanagement

Wir laden zun√§chst die f√ºr dieses Skript ben√∂tigten Pakete und legen unseren Grafikhintegrund sowie die Formatierung von Zahlen fest.

```{r}
if(!require("pacman")) {install.packages("pacman");library(pacman)}
p_load(knitr,car, tidyverse, ggplot2, ggpubr, effectsize, DescTools, dplyr,afex, emmeans, PMCMRplus, sjmisc) #<1>

theme_set(theme_classic()) #<2>
options(scipen = 999) #<3>
options(es.use_symbols = TRUE) #<4>
```

1.  L√§dt alle ben√∂tigten Pakete mit dem Befehl `p_load()`
2.  Setzt einen universalen Hintergund (`theme_classic`) f√ºr unsere Datenvisualisierungen mit ggplot2 fest.
3.  Sorgt daf√ºr, dass sehr kleine Zahlen ausgeschrieben werden.
4.  Sorgt daf√ºr, dass Symbole im Output gedruckt werden.

Anschlie√üend laden wir unseren Datensatz:

```{r}
daten = haven::read_dta("Datensatz/Allbus_2021.dta")
```

Um mit dem Datensatz arbeiten zu k√∂nnen ben√∂tigen wir einige grundlegende Schritte des Datenmanagements [f√ºr ausf√ºhrliche Erkl√§rungen siehe hier](https://patrickzerrer.github.io/R_Hands_on_Book/Skript_3.3.html). F√ºr die Varianzanalyse m√∂chten wir uns anschauen, wie sich der Gesundheitszustand (und das Alter) der Befragten auf ihr Vertrauen in das Gesundheitswesen auswirkt. Wir nutzen dazu die folgenden Variablen:

+--------------+-----------------------------------+-------------------------+
| Variable     | Beschreibung                      | Auspr√§gungen            |
+:============:+:=================================:+:=======================:+
| hs01         | Gesundheitszustand der Befragten  | -42 = Datenfehler       |
|              |                                   |                         |
|              |                                   | -11 = TNZ Split         |
|              |                                   |                         |
|              |                                   | -9 = Keine Angabe       |
|              |                                   |                         |
|              |                                   | 1 = Sehr Gut            |
|              |                                   |                         |
|              |                                   | 2 = Gut                 |
|              |                                   |                         |
|              |                                   | 3 = Zufriedenstellend   |
|              |                                   |                         |
|              |                                   | 4 = Weniger Gut         |
|              |                                   |                         |
|              |                                   | 5 = Schlecht            |
+--------------+-----------------------------------+-------------------------+
| age          | Alter der Befragten               | -32 = Nicht Generierbar |
+--------------+-----------------------------------+-------------------------+
| pt01         | Vertrauen in das Gesundheitswesen | -42 = Datenfehler       |
|              |                                   |                         |
|              |                                   | -11 = TNZ Split         |
|              |                                   |                         |
|              |                                   | -9 = Keine Angabe       |
|              |                                   |                         |
|              |                                   | 1 = Gar kein Vertrauen  |
|              |                                   |                         |
|              |                                   | ...                     |
|              |                                   |                         |
|              |                                   | 7 = Gro√ües Vertrauen    |
+--------------+-----------------------------------+-------------------------+

Innerhalb unseres Datenmanagements schlie√üen wir fehlerhafte und fehlende Werte der Variablen sex, agef und pt12 aus und benennen falls n√∂tig die Variablen um:

```{r}

daten <- daten %>%
  filter(., hs01 > 0 & pt01 > 0 & age > 0) %>% #<1>
  rename(., gesund = hs01, #<2>
            trustges = pt01) %>% 
  mutate(gesund = haven::as_factor(gesund), #<3>
         trustges = as.numeric(trustges),
         agef = dicho(age, as.num = T) %>% factor(levels = c(0,1), labels = c("jung", "alt"))) #<4>

```

1.  Wir schlie√üend fehlende Werte (siehe Tabelle oben aus). Da diese alle negativ sind, k√∂nnen wir einfach alle Werte kleiner als 0 ausschlie√üen.
2.  Hier benennen wir die Variablen anders um unsere weitere Arbeit zu vereinfachen.
3.  Wir speichern die Variablen als Faktoren. Wir nutzen dabei die Funktion as_factor aus dem haven Paket um die Bezeichnungen der Faktorstufen direkt zu √ºbernehmen.
4.  Wir kodieren die Variable Alter in eine dichotome Variable (jung und alt) um. Die Aufteilung geschieht anhand des Medians der Verteilung.

# Voraussetzungspr√ºfung f√ºr einfaktorielle und mehrfaktorielle Varianzanalyse

Die Varianzanalyse ist ein statistisches Verfahren, dass bestimmte Voraussetzungen bez√ºglich der abh√§ngigen und unabh√§ngigen Variablen voraussetzt. Dies sind im √úberblick:

-   Datenniveau der AV (metrisch) und UV (Faktor)
-   Normalverteilung der abh√§ngiven Variablen
-   Homogenit√§t der Fehlervarianzen der unabh√§ngigen Variablen

Die meisten Voraussetzungen, die f√ºr die Durchf√ºhrung und Interpretation einer Varianzanalyse erf√ºllt sein m√ºssen, lassen sich bereits im Vorfeld der eigentlichen Analyse √ºberpr√ºfen. So kann das Messniveau unmitttelbar festgestellt werden. Es gilt f√ºr die *abh√§ngige (y-)Variable* stets, dass sie *intervallskaliert* sein muss, in R also als ein Vektor vorliegen muss. Die Faktoren bzw. *unabh√§ngige(n) (x-) Variable(n)* hingegen m√ºssen zwingend nominalskaliert sein und in R demnach als *Faktoren* vorliegen.

## √úberpr√ºfung der Normalverteilung

Eine weitere wichtige, leicht vorab zu pr√ºfende Bedingung, die f√ºr eine Varianzanalyse erf√ºllt sein muss, ist die **Normalverteilung der abh√§ngigen Variable**. Diese k√∂nnen wir graphisch √ºberpr√ºfen:

```{r}
#Histogramm ausgeben
ggplot(daten, aes(trustges)) + #<1>
  geom_histogram(aes(y = after_stat(count)), #<2>
                 color = "black", fill = "grey", 
                 binwidth = 1) + #<3>
  labs(x = "Vertrauen in das Gesundheitswesen", #<4>
         y = "")
```

1.  In R nutzen wir das Paket `ggplot2` von Wickham et al. um ein Histogramm auszugeben. Zun√§chst m√ºssen wir hier das Paket `ggplot2` mit dem Befehl `ggplot()` aufrufen. Anschlie√üend spezifizieren wir innerhalb der Klammer unseren Datensatz (hier `daten`) und unter aes unsere Variable (hier `trustges`).
2.  Die Spezifizierungen innerhalb der Klammern unseres Histogramms geben an, dass dieses auf den Zahlen unseres Datensatzes beruhen soll `(aes(y = after_stat(count))`, wir die Au√üenumrandung schwarz `color = black` und die F√ºllfarbe grau w√ºnschen (`fill = grey`). Diese Spezifikationen sind optional, sorgen jedoch f√ºr ein sch√∂neres Aussehen unserer Grafik.
3.  Mit `binwidth = 1` verweisen wir hier auf die Breite der Balken unseres Histogramms.
4.  F√ºr ein versch√∂nertes Aussehen unseres Graphen nutzen wir den Befehl `labs` um zus√§tzlich die Achsen zu beschriften.

Wir sehen an der Grafik, dass die Variable Vertrauen in das Gesundheitswesen rechtssteil ist, also die Teilnehmer der Befragung eher ein h√∂heres Vertrauen angegeben haben.

Zus√§tzliche Gewissheit bez√ºglich des Vorliegens der Normalverteilung bietet der *Kolmogorov-Smirnov-Test* oder der *Shapiro-Wilk-Test* (welcher f√ºr kleinere Stichproben zwischen 3 und 5000 F√§llen konzipiert ist). In R erhalten wir diese Tests mit dem Befehl `LillieTest()` aus dem Paket `DescTools()` bzw. `shapiro.test()`. Beide Tests testen auf Abweichung von der Normalverteilung, demnach sollte diese nicht signifikant ausfallen (da ein signifikanter Test aussagt, dass eine Abweichung von der Normalverteilung besteht, was wir nicht m√∂chten).

```{r}
LillieTest(daten$trustges)
shapiro.test(daten$trustges)
```

Im vorliegenden Beispiel sind beide Tests signifikant. Allerdings reagieren beide Tests insbesondere bei gro√üen Stichproben sehr sensibel, sodass bereits leichte Abweichungen von der Normalverteilung (etwa durch Ausrei√üer) die Tests signifikant werden lassen; in diesen F√§llen ist es sinnvoll eher auf die graphische √úberpr√ºfung (siehe oben) zu schauen. Sowohl der Kolmogorov-Smirnov-Test als auch die Grafik lassen jedoch nicht auf eine perfekte Normalverteilung unserer abh√§ngigen Variablen schlie√üen. In diesem Fall kann die Varianzanalyse dennoch gerechnet werden, da solange die Verteilung nicht extrem steil ist, das Verfahren einigerma√üen robust ist. Bei einer sehr starken Verletzung der Normalverteilung m√ºsste ggf. auf nicht parametrische Tests wie den [Kruskal-Wallis-Test](https://patrickzerrer.github.io/R_Hands_on_Book/Skript_6.4.html#exkurs-kruskal-wallis-test) ausgewichen werden.

## √úberpr√ºfung der Homogenit√§t der Fehlervarianzen

Die letzte Voraussetzung, die f√ºr eine Varianzanalyse erf√ºllt sein muss, ist die Homogenit√§t der Fehlervarianzen. Um diese zu testen, nutzen wir den Levene-Test auf Varianzhomogenit√§t. Hierf√ºr nutzen wir die Funktion `leveneTest()`aus dem Paket `car`.

```{r}
#Levene-Test f√ºr einfaktorielle Varianzanalyse
daten %>% 
  leveneTest(trustges ~ gesund, data = ., center = mean) #<1>

#Levene-Test f√ºr mehrfaktorielle Varianzanalyse ausgeben
daten %>% 
  leveneTest(trustges ~ gesund*agef, data = ., center = mean) #<2>

```

1.  Innerhalb der Klammer m√ºssen wir zun√§chst unsere abh√§ngige Variable angeben. Danach folgt eine Tilde (\~). Im Anschluss m√ºssen wir unsere unabh√§ngige(n) Variablen angeben. Die Tilde sagt quasi, dass unsere abh√§ngige Variable durch unsere unabh√§ngigen Variablen bestimmt wird. Haben wir nur eine abh√§ngige Variable, so geben wir diese an.
2.  Haben wir mehrere unabh√§ngige Variablen so k√∂nnen wir diese mit einem \* verbinden. Anschlie√üend wird der Test f√ºr beide Variablen sowie den Interaktionsterm ausgeben.

Wenn der Levene-Test statistisch signifikant ausf√§llt, sollte die Hypothese homogener Varianzen abgelehnt werden. Falls der Test wie im vorliegenden Fall signifikant ausf√§llt (da der `Pr(>F-Wert)` kleiner als 0.05 ist) wurde die Voraussetzung der Homogenit√§t der Fehlervarianzen verletzt. In einem solchen Fall k√∂nnen wir wahlweise auf nicht-parametrische Tests ausweichen, oder die Varianzanalyse dennoch berechnen, wenn wahlweise die deskriptiven Kennwerte keine allzu gro√üe Streuung aufweisen, oder wir einen alternativen Posthoc-Test wie Tamhame T2 w√§hlen.

# Einfaktorielle Varianzanalyse (ohne Messwiederholung)

Nachdem wir die Voraussetzungen gepr√ºft haben, schauen wir uns die einfaktorielle Varianzanalyse an. Im vorliegenden Beispiel m√∂chten wir √ºberpr√ºfen, inwiefern sich der Gesundheitszustand (Variable `gesund`; Von sehr gut bis schlecht) auf das Vertrauen in das Gesundheitswesen (Variable `trustges`) auswirkt.

## Deskriptive Statistiken

Zun√§chst interessieren uns die deskriptiven Statistiken. Daf√ºr gruppieren wir die Ergebnisse unserer abh√§ngigen Variablen anhand der Auspr√§gungen unserer unabh√§ngigen Variablen und lassen uns jeweils den Mittelwert und die Standardabweichung ausgeben.

```{r}
daten %>% 
  group_by(gesund) %>% #<1>
  summarise(Mittelwert = mean(trustges, na.rm = T), #<1>
            Standardabweichung = sd(trustges, na.rm = T)) %>% 
  kable(digits = 2, col.names = c("Gesundheitszustand", "M", "SD"), caption = "Descriptives Vertrauen") #<2>
```

1.  Zun√§chst m√∂chten wir uns anhand von deskriptiven Statistiken einen √úberblick √ºber unsere Daten verschaffen. Daf√ºr nutzen wir die `group_by`-Funktion in Kombination mit der `summarise`-Funktion.
2.  Im nachfolgenden Schritt haben wir mit Hilfe des Befehls `kable()` aus dem Paket `knitr` das Aussehen unserer Tabelle versch√∂nert. Dieser Schritt ist optional.

Anhand der deskriptiven Statistiken sehen wir, dass das Vertrauen in das Gesundheitswesen am h√∂chsten ausgepr√§gt ist, bei Personen die einen guten Gesundheitszustand aufweisen. Ob dieser augenscheinliche Unterschied auch statistisch signifikant ist, m√∂chten wir in einem n√§chsten Schritt mit der einfaktoriellen ANOVA berechnen.

## Durchf√ºhren der Varianzanalyse

Zur Berechnung der Varianzanalye nutzen wir die Funktion `aov_car` aus dem `afex`-Paket:

```{r}
#Einfaktorielle ANOVA
fit <- daten %>% 
aov_car(trustges ~ gesund + Error(respid), data = ., anova_table = "pes") #<1>

print(fit)

eta_squared(fit, partial = F) #<2>
```

1.  Innerhalb der Funktion aov_car m√ºssen wir zun√§chst die abh√§ngige Variable (`trustges`) angeben und nach einer Tilde die unabh√§ngige Variabel (`gesund`). Zudem m√ºssen wir den Zusatz `+ Error()` nutzen un in der Klammer die Fallid (hier `respid`) angeben. Alles speichern wir als Objekt `fit` welches wir anschlie√üend mit `print` aufrufen.
2.  Mit `eta_squared` k√∂nnen wir zus√§tzlich die Effektst√§rke angeben. Diese findet sich f√ºr die einfaktorielle Anova auch in der Spalte pes, aber hier erhalten wir zus√§tzlich ein Konfidenzintervall f√ºr den Effekt.

## Interpretation des Outputs

Als Output erhalten wir eine Tabelle, deren einzelne Bestandteile im Folgenden n√§her erl√§utert und interpretiert werden.

*Effect* zeigt die unabh√§ngige Variable des Modells, in diesem Fall die Variable Gesundheitszustand(`gesund`). Die vier bedeutet, dass hier insgesamt eine Gruppe mit 4 anderen (= f√ºnf Auspr√§gungen) verglichen wurde.

√úber die Werte der zweiten und vierten Spalte, die *Freiheitsgrade* (`df`) und die *F-Werte* (`F`) lie√üe sich, wenn man es wollte, der emprische F-Wert in der F-Tabelle, mit dem kritischen Wert (theoretischen F-Wert) vergleichen, um zu pr√ºfen, ob die Nullhypothese, dass keine Unterschiede zwischen den durch die jeweilige Variable definierten Gruppen bestehen, verworfen werden darf. Diesen Aufwand kann man sich allerdings sparen, da R in der Spalte `p.value` die umgekehrte Aussage macht, dass die Nullhypothese mit der dort berichteten Fehlerwahrscheinlichkeit verworfen werden kann. Beim per Konvention in den Sozialwissenschaften mindestens geltenden Konfidenz-Niveau von 95%, d√ºrfen im Umkehrschluss also f√ºr alle Modellterme signifikante Unterschiede in der Grundgesamtheit angenommen werden, die hier einen Wert \<.05 aufweisen. Die Spalte ist damit die wichtigste der gesamten Tabelle! Im vorliegenden Datenbeispiel ist demnach ein signifikanter Unterschied des Gesundheitszustandes im Bezug auf das Vertrauen in das Gesundheitswesen ersichtlich.

Die *mittlere quadratische Abweichung (MSE)* oder Fehlervarianz ist die Summe der Abweichungsquadrate aller Werte vom jeweiligen Gruppenmittelwert. Berechnet wird diese durch die Quadratsummer der Fehlerresiduen geteilt durch die Freiheitsgrade. Sie gibt damit die Varianz innerhalb der einzelnen Gruppen (=nicht erkl√§rte Varianz) wieder.

Die Spalte *pes* steht f√ºr das partielle Eta-Quadrat und gibt die Erkl√§rungskraft der einzelnen Faktoren im Hinblick auf die anh√§ngige Variable an -- partiell ist das Eta^2^, da es um die Einfl√ºsse der √ºbrigen Modellgr√∂√üen bereinigt ist (f√ºr unifaktorielle Analysen wie im vorliegenden Fall ist dies nicht relevant, allerdings f√ºr die multifaktorielle ANOVA). Die Effektst√§rke betr√§gt 0.006 und entspricht damit einem sehr kleinen Effekt (Cohen, 1988). Im Datenbeispiel hat demnach der Gesundheitszustand (und damit auch unser Gesamtmodell) eine Erkl√§rkraft von lediglich 0.6 Prozent f√ºr Unterschiede im Vertrauen auf das Gesundheitssystem. Allerdings wissen wir lediglich, dass sich unsere Gruppen signifikant unterscheiden, nicht jedoch, ob sich alle Gruppen unterscheiden, oder lediglich einzelne. Daher ben√∂tigen wir die Posthoc-Tests.

## PostHocTests

Zuletzt m√ºssen wir die Posthoc-Tests berechnen, welche uns Aufschluss dar√ºber geben, welche unserer Gruppen sich unterscheiden. Es gibt verschiedene Posthoc-Tests. Grunds√§tzlich ist der Tukex-Post-Hoc Test zu empfehlen, welche wir √ºber die Funktion `emmeans`aus dem `emmeans`-Package aufrufen:

```{r}
emmeans::emmeans(fit, specs = "gesund") %>% #<1>
  pairs()
```

1.  Innerhalb von emmeans k√∂nnen wir einfach auf unser zuvor spezifiziertes Modell fit verweisen, m√ºssen allerdings noch mit `specs=` angeben, auf Basis welcher Variablen der Gruppenvergleich durchgef√ºhrt werden soll.

Bei fehlender Varianzhomogenit√§t k√∂nnen wir zudem den tamhane-T2 Test nutzen. Dieser basiert allerdings auf einem aov-Objekt, daher geben wir hier mit aov die ANOVA erneut aus.

```{r}
daten %>% 
aov(trustges ~ gesund, data = .) %>% 
  tamhaneT2Test(.)
```

## Interpretation der Posthoc-Tests und des Gesamtmodells

Hier interessiert uns jeweils der p-value (f√ºr den Tamhame T2 Test wird uns nur dieser angezeigt). Werte unter .05 bedeuten, dass zwischen diesen Gruppen ein signifikanter Mittelwertunterschied besteht.

In unserem Beispiel sehen wir signifikante Unterschiede zwischen Personen die einen sehr guten Gesundheitszustand aufweisen und Personen, denen es gesundheitlich schlechter geht (Kategorien zufriedenstellender Gesundheitszustand, weniger guter Gesundheitszustand und je nach Test schlechter Gesundheitszustand). Dementsprechend ist der Gesundheitszustand ein signifikanter Faktor um das Vertrauen in das Gesundheitswesen vorherzusagen. Hier sind jedoch lediglich gravierende Unterschiede in der eigenen Gesundheitseinsch√§tzung ma√ügeblich f√ºr Unterschiede in das Vertrauen.

## Visualisierung der Gruppenunterschiede mittels Fehlerbalken

Oftmals lohnt es sich, die Ergebnisse der Varianzanalyse auch graphisch darzustellen. Hierzu nutzen wir Fehlerbalkendiagramme:

```{r}
daten %>% 
  ggline(x= "gesund", #<1>
         y = "trustges", #<1>
         add = "mean_ci", #<2>
         title = "Vertrauen in das Gesundheitswesen", #<3>
         xlab = "Gesundheitszustand", #<3>
         ylab = "Vertrauen in das Gesundheitswesen") + #<3>
  rotate_x_text(45) #<4>
```

1.  Wir w√§hlen auf der x-Achse die Variable `gesund` aus und auf der y-Achse die Variable `trustges`.
2.  Wir f√ºgen f√ºr die jeweiligen Faktorstufen der Variablen `gesund` die Mittelwerte sowie Konfidenzintervalle hinzu.
3.  Wir bennenen unsere Grafik um.
4.  Da die Labels unserer Faktorstufen sehr lang sind, drehen wir diese um 45 Grad. Dies geschieht mit der Funktion `rotate_x_text()` aus dem Paket `ggpubr`.

Die Punkte in der Grafik visualisieren die Mittelwerte der einzelnen Gesundheitszust√§nde mit Bezug auf die Variable Vertrauen in das Gesundheitswesen. Um die Punkte sind jeweils mit Strichen die Konfidenzintervalle eingezeichnet. Wenn sich die Bereich der Konfidenzintervalle nicht √ºberschneiden, besteht ein signifikanter Mittelwertunterschied.

Daher k√∂nnen wir anhand der Grafik ablesen, dass das Vertrauen in das Gesundheitswesen am h√∂chsten bei Personen mit einem sehr guten Gesundheitszustand ist und sukkzessive abnimmt, je schlechter der Gesundheitszustand der Befragten ausf√§llt. Auch die Ergebnisse aus den Posthoc-Tests zeigen sich innerhalb der Grafik: Die Konfidenzintervalle von Personen mit einem sehr guten Gesundheitszustand und einem zufriedenstellenden und weniger guten √ºberschneiden sich nicht. Insofern finden wir bei diesen Gruppen signifikante Mittelwertunterschiede.

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse der Varianzanalyse werden zumeist in Textform dargestellt. Daf√ºr werden folgende Informationen ben√∂tigt:

‚úÖ die Mittelwerte und Standardabweichung der einzelnen Faktorstufen

‚úÖ der df-Wert

‚úÖ der F-Wert

‚úÖ der p-Wert

‚úÖ der pes-Wert

‚úÖ die Posthoc-Test Ergebnisse

Das Format ist √ºblicherweise:

> ***Beispiel:*** Personen mit einem sehr guten Gesundheitszustand haben durchschnittlich ein h√∂heres Vertrauen in das Gesundheitswesen (M = 5.13;SD=1.45) als Personen mit einem guten (M = 4.99;SD=1.32), zufriedenstellenden (M = 4.85;SD=1.37), weniger guten (M = 4.82;SD=1.48) oder schlechtem (M = 4.71;SD=1.55) Gesundheitszustand . Der Gesundheitszustand hat dabei einen signifikanten Einfluss auf das Vertrauen in das Gesundheitswesen (F3470)=5,46,p\<0,001. Die Effektst√§rke nach Cohen (1992) liegt bei alpha=0,006 und entspricht einem kleinen Effekt. Post-Hoc Paarvergleiche mit Tamhames ergaben, dass sich der Mittelwert f√ºr die Personen mit sehr guten Gesundheitszustand signifikant von den Personen mit zufriedenstellendem (p\<0.029) und weniger gutem (p\<0.0174) Zustand unterscheidet. Die anderen Gesundheitsgruppen unterscheiden sich hingegen nicht signifikant voneinander.
:::

## Exkurs: nicht parametrische Testverfahren

Wenn wir die Voraussetzungen der Varianzanalyse nicht erf√ºllen, k√∂nnen wir statt der Varianzanalyse den Kruskal-Wallis Test rechnen. Hierf√ºr m√ºssen unsere Daten nicht die Voraussetzungen der Normalverteilung sowie der Homogenit√§t der Fehlervarianzen erf√ºllen.

Den Kruskal-Wallis-Test rufen wir mit der Funktion `kruskal.test()` auf:

```{r}
kruskal.test(trustges ~ gesund, data = daten)
```

Hier interessiert uns insbesondere der p-Wert. Wir sehen, wie auch in der Varianzanalyse, dass sich unsere Gruppen signifikant voneinander unterscheiden. Im Anschluss m√ºssen wir dann erneut die Posthoc Tests durchf√ºhren.

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse des Kruskal-Wallis Tests werden simultan zur Varianzanalyse in Textform angegeben. Daf√ºr werden folgende Informationen ben√∂tigt:

‚úÖ die Mittelwerte und Standardabweichung der einzelnen Faktorstufen

‚úÖ der df-Wert

‚úÖ der chi-squared-Wert

‚úÖ der p-Wert

‚úÖ die Posthoc-Test Ergebnisse

Das Format ist √ºblicherweise:

> ***Beispiel:*** Personen mit einem sehr guten Gesundheitszustand haben durchschnittlich ein h√∂heres Vertrauen in das Gesundheitswesen (M = 5.13;SD=1.45) als Personen mit einem guten (M = 4.99;SD=1.32), zufriedenstellenden (M = 4.85;SD=1.37), weniger guten (M = 4.82;SD=1.48) oder schlechtem (M = 4.71;SD=1.55) Gesundheitszustand . Der Gesundheitszustand hat dabei einen signifikanten Einfluss auf das Vertrauen in das Gesundheitswesen H(4) = 25.191, p \< 0.001. Post-Hoc Paarvergleiche mit Tamhames ergaben, dass sich der Mittelwert f√ºr die Personen mit sehr guten Gesundheitszustand signifikant von den Personen mit zufriedenstellendem (p\<0.029) und weniger gutem (p\<0.0174) Zustand unterscheidet. Die anderen Gesundheitsgruppen unterscheiden sich hingegen nicht signifikant voneinander.
:::

::: {.callout-note collapse="true" icon="false"}
## Exkurs: Einfaktorielle Varianzanalyse mit Messwiederholung

## Umgang mit Messwiederholungen

Haben wir mehr als zwei Testzeitpunkte vorliegen, so k√∂nnen wir die ANOVA mit Messwiederholung rechnen. Die ANOVA mit Messwiederholung weitet dabei den Gedanken der t-Test f√ºr abh√§ngige Stichproben weiter aus. Solltet ihr euch f√ºr dieses Verfahren interessieren, findet ihr [hier](https://bjoernwalther.com/anova-mit-messwiederholung-in-r/) weitere Infos dazu.
:::

# Mehrfaktorielle Varianzanalyse

In der mehrfaktoriellen Varianzanalyse haben wir eine abh√§ngige Variable und mehrere unabh√§ngige Variablen. Um diese durchzuf√ºhren, k√∂nnen wir unser Modell aus der einfachen Varianzananlyse einfach um weitere Variablen erweitern. In diesem Beispiel nutzen wir neben der Variablen zum Gesundheitszustand (`gesund`) zus√§tzlich die Variable Alter (`agef`) um das Vertrauen in das Gesundheitssystem (`trustges`) vorherzusagen.

Zun√§chst m√∂chten wir uns anhand von deskriptiven Statistiken einen √úberblick √ºber unsere Daten verschaffen. Daf√ºr schauen wir uns einem ersten Schritt gesondert die Variable Alter an:

```{r}
daten %>% 
  group_by(agef) %>% 
  summarise(Mittelwert = mean(trustges, na.rm = T), 
            Standardabweichung = SD(trustges, na.rm = T)) %>% 
  kable(digits = 2, col.names = c("Alter", "M", "SD"), caption = "Descriptives Vertrauen")
```

Wir sehen, dass √§ltere Menschen grunds√§tzlich ein h√∂heres Vertrauen in das Gesundheitswesen haben, als j√ºngere Menschen. Anschlie√üend gruppieren wir unsere deskriptiven Statistiken anhand unserer beiden unabh√§ngigen Variablen Alter und Gesundheitszustand:

```{r}
daten %>% 
  group_by(gesund, agef) %>% 
  summarise(Mittelwert = mean(trustges, na.rm = T), 
            Standardabweichung = SD(trustges, na.rm = T)) %>% 
  kable(digits = 2, col.names = c("Gesundheitszustand", "Alter", "M", "SD"), caption = "Descriptives Vertrauen")
```

In dieser Tabelle sehen wir das Vertrauen in das Gesundheitssystem in Abh√§ngigkeit von dem Gesundheitszustand der Befragten sowie ihrem Alter, wobei insbesondere die Unterchiede in den Mittelwerten von Interesse sind. Diese Mittelwerte im Flie√ütext kurz zu erw√§hnen, geh√∂rt zum ‚Äûguten Ton" bei der Auswertung einer Varianzanalyse und sollte daher nicht vergessen werden.

Nun k√∂nnen wir unsere ANOVA aufstellen. Es gibt verschiedene M√∂glichkeiten eine ANOVA zu berechnen, namentlich Type I, II und III. Die einzelnen Typen unterscheiden sich darin, wie die Parameter (insbesondere die Quadratsumme) berechnet wird. Typ I sollte vor allem f√ºr ausgeglichene Daten verwendet werden, also Daten bei der f√ºr jede Gruppe die gleiche Anzahl an F√§llen vorliegen. Ist dies nicht der Fall, sollte Typ II oder Typ III (beispielsweise die Option der Anova in SPSS) verwendet werden. Der typische Befehl f√ºr eine Anova in R ist der Befehl `aov()`. Dieser ist jedoch nur f√ºr die Typ I Anova ausgelegt, daher nutzen wir hier erneut den Befehl `aov_car()` (sowie den distict-Befehl) aus dem `afex`-Paket welcher standardm√§√üig die Anova nach Typ III berechnet. Im Prinzip nutzen wir die selbe Syntax wie bei der unifaktoriellen Anova. Wir erg√§nzen allerdings unsere zweitere unabh√§ngige Variable, beziehungsweise verbinden die beiden unabh√§ngigen Variablen mit einem \*. Dadurch erhalten wir sowohl die Werte f√ºr die einzelnen Variablen als auch f√ºr den Interaktionsterm, also das Zusammenspiel der Variablen.

```{r}
fit2 <- daten %>% 
  afex::aov_car(trustges ~ gesund * agef + Error(respid),
                                     data = ., anova_table = "pes")
print(fit2)
```

## Interpretation des Outputs

Die Erl√§uterungen der einzelnen Parameter sind gleich zu den Erl√§uterungen der unifaktoriellen ANOVA, daher werden diese nicht wiederholt. Es zeigt sich, dass der Gesundheitszustand erneut einen signifikanten Einfluss (`p<.001`) auf das Vertrauen in das Gesundheitswesen hat (welcher im vorliegenden Modell etwas h√∂her mit 0.9 Prozent erkl√§rter Varianz ausf√§llt). Zus√§tzlich hat neben der Gesundheitszustand auch das Alter der Befragten einen signifikanten (`p<.001`), wenngleich geringeren Einfluss auf das Vertrauen in das Gesundheitswesen. Zudem sehen wir einen signifikanten Einfluss der Interaktion von Alter und Gesundheitszustand (`p = .020`).

Im Anschluss m√ºssen wir, wie in der univariaten ANOVA, die Posthoc-Tests berechnen (im vorliegenden Fall k√∂nnen wir lediglich den Tukey-Test berechnen, das der Tamhame-Test nur f√ºr einfaktorielle Designs funktioniert).

### Post-Hoc Tests

```{r}
emmeans::emmeans(fit2, specs = c("gesund", "agef")) %>% 
  pairs() 
```

## Interpretation der Posthoc-Tests und des Gesamtmodells

Die Tabelle zu den Posthoc-Tests ist erwartungsgem√§√ü sehr lang, da alle unsere einzelnen Gruppen miteinander verglichen werden m√ºssen. Hier zeigt sich bereits, dass die mehrfaktorielle Varianzanalyse nur dann Sinn ergibt, wenn unsere Variablen nicht zu viele Auspr√§gungen aufweisen.

Erneut konzentrieren wir uns vorrangig auf die Signifikanzwerte. Wenn wir uns nur auf die junge Altersgruppe konzentrieren, erkennen wir die bereits bekannten Gruppenunterschieden aus der einfaktoriellen Varianzanalyse (zwischen Personen die einen sehr guten Gesundheitszustand aufweisen und Personen, mit einem zufriedenstellenden und weniger guten Gesundheitszustand) wieder. Des Weiteren zeigen sich signifikante Gruppenunterschiede zwischen jungen und alten Personen, die einen guten Gesundheitszustand aufweisen, sowie jungen Personen die einen zufriedenstellenen oder weniger guten Gesundheitszustand haben und alten Personen die einen sehr guten, guten, zufriedenstellenden oder weniger guten Gesundheitszustand haben.

Dementsprechend ist das Alter sowie der Gesundheitszustand ein signifikanter Vorhersagefaktor wobei sich eine Vielzahl an Gruppen signifikant unterscheiden. Insbesondere bei solch komplexen Gruppenunterschieden ist es sinnvoll, die Ergebnisse auch einmal zu visualisieren.

## Visualisierung der Interaktionen

Um einen m√∂glichen Interaktionseffekt auch anschaulich vermitteln bzw. oft auch verstehen zu k√∂nnen, empfiehlt es sich, diesen als Diagramm darzustellen. Hierzu nutzen wir die Pakete `emmeans` und `ggplot2`.

```{r}
#Interaktionsplot ausgeben
emmip(fit2, agef ~ gesund) + #<1>
  labs(title = "Gesch√§tzes Randmittel von Vertrauen in das Gesundheitswesen", #<2>
       y = "Gesch√§tzte Randmittel",
       x = "Gesundheitszustand") +
  scale_color_manual(values = c("darkgreen", "tan4"), name = "Altersgruppe") + #<3>
  rotate_x_text(45) #<4>
```

1.  Innerhalb von `emmip` geben wir zun√§chst unser Modell der Varianzanalyse an und spezifizieren anschlie√üend durch eine Tilde getrennt unsere Variablen. Die Reihenfolge der Variablen kann hier gerne variiert werden um anschlie√üend zu schauen, wierum man die Grafik besser interpretieren kann.
2.  Mit `labs` geben die Bezeichnung f√ºr den Titel sowie die Achsen der Grafik an.
3.  Mit `scale_color_manual` legen wir eigene Farben f√ºr unseren Plot fest. Mittels `name = "Altersgruppe"` √§ndern wir den Titel der Plotlegende.\
4.  Wir drehen unsere Grafikbeschriftung der x-Achse um 45 Grad, damit auch lange Labels lesbar sind.

Anhand der Grafik werden die Interaktionseffekte sowie die Gruppenunterschiede der Posthoc-Tests noch einmal verdeutlicht: W√§hrend bei jungen Personen mit einem sehr guten Gesundheitszustand das Vertrauen in das Gesundheitswesen am h√∂chsten ausgepr√§gt ist, nimmt dieses anschlie√üend steil ab. Bei √§lteren Menschen wiederum ist das Vertrauen in das Gesundheitswesen bei Personen mit einem sehr guten Gesundheitszustand zwar geringer als bei j√ºngeren Personen mit einem sehr guten Gesundheitszustand, nimmt anschlie√üend aber zu und im weiteren Verlauf weit weniger drastisch ab. Daher wird auch deutlich, weswegen wir eine solch hohe Anzahl an signifikanten Gruppenunterschieden zwischen den verschiedenen Gesundheitszust√§nden bei alten und jungen Leuten finden konnten.

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse der mehrfaktoriellen Varianzanalyse werden zumeist in Textform dargestellt. Daf√ºr werden folgende Informationen ben√∂tigt:

‚úÖ die Mittelwerte und Standardabweichung der einzelnen Faktorstufen

‚úÖ der df-Wert

‚úÖ der F-Wert

‚úÖ der p-Wert

‚úÖ die jeweiligen pes-Wert

‚úÖ die Posthoc-Test Ergebnisse

Das Format ist √ºblicherweise:

> ***Beispiel:*** Personen mit einem sehr guten Gesundheitszustand haben durchschnittlich ein h√∂heres Vertrauen in das Gesundheitswesen (M = 5.13;SD=1.45) als Personen mit einem guten (M = 4.99;SD=1.32), zufriedenstellenden (M = 4.85;SD=1.37), weniger guten (M = 4.82;SD=1.48) oder schlechtem (M = 4.71;SD=1.55) Gesundheitszustand. Des Weiteren haben √§ltere Personen ein h√∂heres Vertrauen in das Gesundheitswesen (M = 5.05;SD=1.36) als j√ºngere Personen (M = 4.85;SD=1.40). Der Gesundheitszustand (F3465)=7,66,p\<0,001 Œ∑p2 = und das Alter (F3465)=14,63,p\<0,001 haben jeweils einen signifikanten Einfluss auf das Vertrauen in das Gesundheitswesen. Post-Hoc Paarvergleiche mit Tukey ergaben, dass sich der Mittelwert f√ºr junge Personen mit sehr guten Gesundheitszustand signifikant von jungen Personen mit gutem (p=.045), zufriedenstellendem (p\<0.001) und weniger gutem (p\<0.001) Zustand unterscheidet. Des Weiteren unterscheiden sich junge Personen mit guten Gesundheitszustand von jungen Personen mit zufriedenstellenden Gesundheitszustand (p=.01) sowie von alten Personen mit guten Gesundheitszustand (p=.018). Dar√ºber hinaus unterscheiden sich junge Personen mit einem zufriedenstellenden Gesundheitszustand von alten Personen mit einem sehr guten (p=.03), guten (p\<0.001), zufriedenstellenden (p\<0.001) und weniger guten (p=.01) Gesundheitszustand. Zuletzt unterscheiden sich junge Personen mit einem weniger guten Gesundheitszustand von alten Personen mit einem guten (p\<0.001), zufriedenstellenden (p.005) und weniger guten Gesundheitszustand (p=.0489). Das Ergebnise zeigt zudem eine signifikante Interaktion von Gesundheitszustand und Alter ((F3465)=2,93, p=0,020, Œ∑p2 = .003) auf das Vertrauen in das Gesundheitswesen. Dies weist darauf hin, dass sich der Gesundheitszustand je nach Altersgruppe unterschiedlich auswirkt. Bei einem sehr guten Gesundheitszustand ist das Vertrauen in das Gesundheitswesen bei jungen Menschen (M = 5.15, SD = 1.42) st√§rker ausgepr√§gt als bei alten Menschen (M = 5.05, SD = 1.57). Bei allen anderen Gesundheitszust√§nden ist es genau umgekehrt. Hier haben jeweils √§ltere Menschen ein h√∂heres Vertrauen in das Gesundheitswesen als j√ºngere Menschen.
:::

## Literatur

::: callout-note
## Literatur und Beispiele aus der Praxis

Wir empfehlen euch folgende Lehrb√ºcher, falls ihr weiterf√ºhrende Informationen braucht.

> üìñ Gehrau, V., Maubach, K., & Fujarski, S. (2022). Einfache Datenauswertung mit R. [Link](https://link.springer.com/book/10.1007/978-3-658-34285-2)

> üìñ Field, Z., Miles, J., & Field, A. (2012). Discovering statistics using R. Discovering statistics using r, 1-992. [Link](https://suche.suub.uni-bremen.de/peid=B68436977&LAN=DE&CID=7699632&index=L&Hitnr=1&dtyp=D&rtyp=a&Exemplar=1)
:::
