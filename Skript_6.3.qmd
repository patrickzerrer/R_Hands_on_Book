---
title: "Die Bestimmung der Zentrale Tendenz mittels t-Tests"
author: "Katharina Maubach"
toc: true
number-sections: true
highlight-style: pygments
execute: 
  message: false
  warning: false
format:
  html:
    code-fold: false
    code-line-numbers: true
    code-annotations: hover
---

![Bild generiert von Midjourney](Bilder/Grafik_ttest.png)

Wir nutzen den t-test um Mittelwertunterschiede zwischen zwei Gruppen zu analysieren. 

::: {.callout-note collapse="true" icon="false"}
## Video

{{< video https://nc.uni-bremen.de/index.php/s/T7brcJ73tLGpCk7/download/%2311%20t-Test.mp4 width="900" height="500">}}
:::

Wir unterscheiden grundsätzlich in zwei verschiedene Arten von t-Test:

-   den t-Test für unabhängige Stichproben (two-paired-test) sowie
-   den t-Test für verbundene Stichprobene (paired test)

**t-test für unabhängige Stichproben**

Mit dem t-test für unabhängige Stichproben überprüfen wir, ob sich die Mittelwerte in zwei gemessenen Stichproben unterscheiden. Die Stichproben sind dann unabhängig, wenn sie aus zwei unterschiedlichen Gruppen stammen und daher sich nicht gegenseitig beeinflussen können. Ein solches Beispiel liegt zum Beispiel dann vor, wenn wir schauen ob das Alter (dichotom kodiert in alt vs jung) einen Einfluss auf das Einkommen hat. In diesem Fall kann eine Person zum Untersuchungszeitpunkt nicht gleichzeitig alt und jung sein, sondern fällt in einer der beiden Gruppen. Ein anderes typisches Anwendungsbespiel ist der Vergleich von zwei Gruppen im Rahmen eines Experimentaldesign. Hier kann ein Proband ebenfalls nur einer der Untersuchungsgruppe zugeordnet sein.

**t-test für verbundene Stichproben**

Der t-test für verbundene Stichproben wiederum misst, inwiefern sich Mittelwerte bei denselben Personen oder Fällen verändern. Wenn wir bei unserem Beispiel mit dem Einflusses des Alters auf das Einkommen bleiben, so könnten wir dieselben Personen zu zwei Zeitpunkten befragen: einmal wenn sie jung sind und dann zu einem späteren Zeitpunkt noch einmal. In diesem Fall sind unsere Stichproben nicht unabhängig, da die Messwerte von denselben Personen stammen und ggf. der frühere Messzeitpunkt den späteren beeinflussen kann.

**Der Einstichprobentest**

Zusätzlich gibt es noch den Einstichprobentest oder auch one-sample-test. Hier vergleichen wir nicht zwei Gruppenmittelwerte miteinander, sondern den Mittelwert einer Gruppe mit einem bereits bekannten feststehenden Wert. Wir können so beispielsweise überprüfen, ob das Einkommen in einer Stichprobe dem deutschlandweiten Mittelwert entspricht, sofern dieser uns vorab bekannt ist.

# t-Test für unabhängige Stichproben

Wir schauen uns zunächst den t-Test für unabhängige Stichproben an.

## Datenmanagement

Wir beginnen mit dem Laden der notwendigen Pakete.

```{r Pakete}
if(!require("pacman")) {install.packages("pacman");library(pacman)}
p_load(tidyverse, ggplot2, haven, mosaic, knitr,effectsize, car, broom) # <1>

theme_set(theme_classic()) # <2>
```

1.  Mittels p_load laden wir alle benötigten Pakete gleichzeitig.
2.  Wir legen allgemein den Hintergrund theme_classic fest.

Anschließend laden wir die Daten aus dem Allbus:

```{r}
daten = haven::read_dta("Datensatz/Allbus_2021.dta")
```

Um mit dem Datensatz zu arbeiten benötigen wir einige grundlegende Schritte des Datenmanagements (für ausführliche Erklärungen siehe [hier](https://patrickzerrer.github.io/R_Hands_on_Book/Skript_3.3.html)). Für unseren t-test für unabhängige Stichproben möchten wir uns anschauen, wie sich der Wohnort der Befragten auf ihr Vertrauen in die Bundesregierung auswirkt. Wir nutzen dazu die folgenden Variablen:

+--------------+----------------------------------+-------------------------------+
| Variable     | Beschreibung                     | Ausprägungen                  |
+:============:+:================================:+:=============================:+
| eastwest     | Erhebungsgebiet West-Ost         | 1= Alte Bundesländer (Westen) |
|              |                                  |                               |
|              |                                  | 2 = Neue Bundesländer (Osten) |
+--------------+----------------------------------+-------------------------------+
| pt12         | Vertrauen in die Bundesregierung | -42 = Datenfehler             |
|              |                                  |                               |
|              |                                  | -11 = TNZ Split               |
|              |                                  |                               |
|              |                                  | -9 = Keine Angabe             |
|              |                                  |                               |
|              |                                  | 1 = Gar kein Vertrauen        |
|              |                                  |                               |
|              |                                  | ...                           |
|              |                                  |                               |
|              |                                  | 7 = Großes Vertrauen          |
+--------------+----------------------------------+-------------------------------+

Innerhalb unseres Datenmanageements schließen wir fehlerhafte und fehlende Werte der Variablen pt12 aus und benennen diese anschließend um:

```{r}

daten <- daten %>%
  filter(., pt12 > 0) %>%  #<1>
  rename(., trustreg = pt12) %>%  #<2>
  mutate(trustreg = as.numeric(trustreg), #<3>
         eastwest = haven::as_factor(eastwest)) #<3>
```

1.  Wir schließend fehlende Werte (siehe Tabelle oben aus). Da diese alle negativ sind, können wir einfach alle Werte kleiner als 0 ausschließen.
2.  Hier benennen wir die Variablen anders um unsere weitere Arbeit zu vereinfachen.
3. Wir bringen unsere Daten in das korrekte Format. Für den t-Test muss die abhängige Variable als Vektor vorliegen und die unabhängige Variable als Faktor. 

## Deskriptives der abhängigen Variablen

Als ersten Schritt schauen wir uns die deskriptiven Statistiken unserer abhängigen Variablen Vertrauen in die Regierung für die beiden Faktorstufen unserer unabhängigen Variablen an.

```{r}
des_stat <- (favstats(trustreg ~ eastwest, data = daten))
rownames(des_stat) <- c("Alte Bundesländer", "Neue Bundesländer")
kable(des_stat[,2:10], digits = 2)
```

Anhand dieser deskriptiven Daten sehen wir, dass das Vertrauen in die Bundesregierung in den alten Bundesländern im Mittelwert mit `4,15` stärker ausgeprägt ist als in den neuen Bundesländern (Mittelwert von `3,86`. Um zu prüfen, ob dieser Unterschied des Mittelwertes statistisch signifikant ist, berechnen wir in einem zweiten Schritt die Teststatistik des t-tests. Zunächst müssen wir jedoch prüfen, ob unsere Daten für die Berechnung geeignet sind. Dazu führen wir eine Voraussetzungsprüfung durch.

## Voraussetzungsprüfung

Bei dem t-test handelt es sich um ein statistisches Verfahren. Um die Güte der Ergebnisse sicherzustellen müssen dabei einige Voraussetzungen beachtet werden.Dies sind im Überblick:

-   die korrekte Skalierung der UV (=Faktor) und AV (=numerisch)
-   die Normalverteilung der abhängigen Variablen
-   die Varianzhomogenität

### Skalierung der UV und AV

Die abhängige Variable muss als numerischer Vektor vorliegen, die unabhängige Variable wiederum als Faktor (mit zwei Ausprägungen). Die korrekte Skalierung der Variablen haben wir bereits innerhalb des Data Managements sichergestellt, können uns aber zusätzlich mit dem Befehl class noch einmal einen Überblick über das Skalenniveau unserer Variablen verschaffen. 

```{r}
daten %>%  
  select(eastwest, trustreg) %>%  
  lapply(class)
```

### Normalverteilung der AV

```{r}
daten  %>%  
  group_by(eastwest) %>%  
  do(tidy(shapiro.test(.$trustreg)))
```

### Varianzhomogenität

```{r}
daten %>%  
  drop_na(eastwest, trustreg) %>% 
  mutate(eastwest = as.factor(eastwest)) %>% 
  leveneTest(trustreg~eastwest, data = .)
```

## Durchführung des t-Tests

```{r}
daten %>% 
  drop_na(eastwest, trustreg) %>%
  filter(.,trustreg >0) %>% 
  t.test(trustreg ~ eastwest,
         alternative = "two.sided", 
         var.equal = T,
         data = .)
```

Effektstärke cohens d berechnen

```{r}

daten %>% 
  drop_na(eastwest, trustreg) %>% 
  cohens_d(trustreg~eastwest, data = .)
```


## Interpretation des Outputs

Der Output des t-tests gibt uns die folgenden Informationen aus:

-   data
-   t
-   df
-   p-value
-   95% confidence intervall
-   means in group 1 & 2

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse des t-tests werden üblicherweise im Text angegeben. Für diese Angabe werden die folgenden Informationen benötigt:

✅ die Mittelwerte und Standardabweichung der einzelnen Vergleichsgruppen

✅ der df-Wert

✅ der F-Wert

✅ der p-Wert

✅ die Effektgröße

Das Format ist üblicherweise:

> ***Beispiel:*** Personen mit einem sehr guten Gesundheitszustand haben durchschnittlich ein höheres Vertrauen in das Gesundheitswesen (M = 5.13;SD=1.45) als Personen mit einem guten (M = 4.99;SD=1.32), zufriedenstellenden (M = 4.85;SD=1.37), weniger guten (M = 4.82;SD=1.48) oder schlechtem (M = 4.71;SD=1.55) Gesundheitszustand . Der Gesundheitszustand hat dabei einen signifikanten Einfluss auf das Vertrauen in das Gesundheitswesen (F3470)=5,46,p\<0,001. Die Effektstärke nach Cohen (1992) liegt bei alpha=0,006 und entspricht einem kleinen Effekt. Post-Hoc Paarvergleiche mit Tamhames ergaben, dass sich der Mittelwert für die Personen mit sehr guten Gesundheitszustand signifikant von den Personen mit zufriedenstellendem (p\<0.029) und weniger gutem (p\<0.0174) Zustand unterscheidet. Die anderen Gesundheitsgruppen unterscheiden sich hingegen nicht signifikant voneinander.
:::

## Nicht-parametrischer Test: Mann-Whitney-U & Wilcoxon-Rangsummen-Test

Wilcoxon-Rangsummentest
[Historie der Testverfahren](http://www.regorz-statistik.de/inhalte/tutorial_wilcoxon_mann_whitney_u_test.html)

# t-Test für verbundene Stichproben

::: {.callout-note collapse="true" icon="false"}
## Voraussetzungsprüfung
:::

## Durchführung des t-tests für verbundene Stichproben

## Nicht-parametrischer Test: Wilcoxon-Vorzeichen-Rangtest



```{r}

pairwise.wilcox.test(daten$trustges, daten$gesund,
                 p.adjust.method = "BH")
```

# t-Test für Einstichproben

Beim t-Test für Einstichproben testen wir, ob die Werte unserer Stichprobe einem vorab festgelegten Wert entsprechen. So können wir beispielsweise mit Blick auf das Einkommen schauen, ob das monatliche Nettoeinkommen aus unserer Stichprobe  dem  Bundesdurchschnitt gemäß dem [statistischen Bundestamt](https://de.statista.com/statistik/daten/studie/261850/umfrage/brutto-und-nettoeinkommen-je-privatem-haushalt-in-deutschland/) von 3813€ entspricht. 

## Data Management

Dazu benennen wir zunächst die entsprechende Variable aus den Allbus-Daten in `einkommen` um und filtern fehlende Werte hinaus. 

```{r}
daten_one <- daten %>% 
  filter(., di01a > 0) %>% 
  rename(., einkommen = di01a)
```

## Voraussetzungsprüfung

Der Einstichprobentest setzt ähnlich wie der two-sided und paired test eine Normalverteilung der abhängigen Variablen voraus. Diese können wir erneut mit dem Shapiro-Wilk-Test überprüfen:

```{r}
daten_one  %>%  
  do(tidy(shapiro.test(.$einkommen)))
```
Da unser Ergebnis signifikant ausfällt, müssen wir hier leider die Normalverteilung unserer AV ablehnen (wir testen ja auf signifikante Abweichung von der Normalverteilung, daher möchten wir bei diesem Test nicht ein signifikantes Ergebnis haben). Um weitere Gewissheit zu erlangen, prüfen wir die Normalverteilung zusätzlich optisch mit einem Histogramm:

```{r}
ggplot(daten_one, aes(einkommen)) + #<1>
  geom_histogram(aes(y = after_stat(count)), #<2>
                 color = "black", fill = "grey", 
                 binwidth = 500) + #<3>
  labs(x = "Netto-Monatseinkommen", #<4>
         y = "")
```

1.  In R nutzen wir das Paket `ggplot2` von Wickham et al. um ein Histogramm auszugeben. Zunächst müssen wir hier das Paket `ggplot2` mit dem Befehl `ggplot()` aufrufen. Anschließend spezifizieren wir innerhalb der Klammer unseren Datensatz (hier `daten_one`) und unter aes unsere Variable (hier `einkommen`).
2.  Die Spezifizierungen innerhalb der Klammern unseres Histogramms geben an, dass dieses auf den Zahlen unseres Datensatzes beruhen soll `(aes(y = after_stat(count))`, wir die Außenumrandung schwarz `color = black` und die Füllfarbe grau wünschen (`fill = grey`). Diese Spezifikationen sind optional, sorgen jedoch für ein schöneres Aussehen unserer Grafik.
3.  Mit `binwidth = 500` verweisen wir hier auf die Breite der Balken unseres Histogramms.
4.  Für ein verschönertes Aussehen unseres Graphen nutzen wir den Befehl `labs` um zusätzlich die Achsen zu beschriften.

Die Grafik verstärkt die Einschätzung des Shapiro-Wilk-Tests, dass keine Normalverteilung vorliegt. In einem solchen Fall würden wir auf den nicht-parametrische one-sample Wilcoxon-Test ausweichen.  

## Durchführung des t-tests für Einstichproben

```{r}
t.test(daten_one$einkommen , mu = 3813)
```
## Nicht-parametrischer Test: one sample Wilcoxon Test

```{r}
wilcox.test(daten_one$einkommen, mu = 3813)
```

