---
title: "Die Bestimmung der Zentrale Tendenz mittels t-Tests"
author: "Katharina Maubach"
toc: true
number-sections: true
highlight-style: pygments
execute: 
  message: false
  warning: false
format:
  html:
    code-fold: false
    code-line-numbers: true
    code-annotations: hover
---

![Bild generiert von Midjourney](Bilder/Grafik_ttest.png)

Wir nutzen den t-test um Mittelwertunterschiede zwischen zwei Gruppen zu analysieren.

::: {.callout-note collapse="true" icon="false"}
## Video

{{< video https://nc.uni-bremen.de/index.php/s/T7brcJ73tLGpCk7/download/%2311%20t-Test.mp4 width="900" height="500">}}
:::

Wir unterscheiden grunds√§tzlich in zwei verschiedene Arten von t-Test:

-   den t-Test f√ºr unabh√§ngige Stichproben (two-paired-test) sowie
-   den t-Test f√ºr verbundene Stichprobene (paired test)

**t-test f√ºr unabh√§ngige Stichproben**

Mit dem t-test f√ºr unabh√§ngige Stichproben √ºberpr√ºfen wir, ob sich die Mittelwerte in zwei gemessenen Stichproben unterscheiden. Die Stichproben sind dann unabh√§ngig, wenn sie aus zwei unterschiedlichen Gruppen stammen und daher sich nicht gegenseitig beeinflussen k√∂nnen. Ein solches Beispiel liegt zum Beispiel dann vor, wenn wir schauen ob das Alter (dichotom kodiert in alt vs jung) einen Einfluss auf das Einkommen hat. In diesem Fall kann eine Person zum Untersuchungszeitpunkt nicht gleichzeitig alt und jung sein, sondern f√§llt in einer der beiden Gruppen. Ein anderes typisches Anwendungsbespiel ist der Vergleich von zwei Gruppen im Rahmen eines Experimentaldesign. Hier kann ein Proband ebenfalls nur einer der Untersuchungsgruppe zugeordnet sein.

**t-test f√ºr verbundene Stichproben**

Der t-test f√ºr verbundene Stichproben wiederum misst, inwiefern sich Mittelwerte bei denselben Personen oder F√§llen ver√§ndern. Wenn wir bei unserem Beispiel mit dem Einflusses des Alters auf das Einkommen bleiben, so k√∂nnten wir dieselben Personen zu zwei Zeitpunkten befragen: einmal wenn sie jung sind und dann zu einem sp√§teren Zeitpunkt noch einmal. In diesem Fall sind unsere Stichproben nicht unabh√§ngig, da die Messwerte von denselben Personen stammen und ggf. der fr√ºhere Messzeitpunkt den sp√§teren beeinflussen kann.

**Der Einstichprobentest**

Zus√§tzlich gibt es noch den Einstichprobentest oder auch one-sample-test. Hier vergleichen wir nicht zwei Gruppenmittelwerte miteinander, sondern den Mittelwert einer Gruppe mit einem bereits bekannten feststehenden Wert. Wir k√∂nnen so beispielsweise √ºberpr√ºfen, ob das Einkommen in einer Stichprobe dem deutschlandweiten Mittelwert entspricht, sofern dieser uns vorab bekannt ist.

# t-Test f√ºr unabh√§ngige Stichproben

Wir schauen uns zun√§chst den t-Test f√ºr unabh√§ngige Stichproben an.

## Datenmanagement

Wir beginnen mit dem Laden der notwendigen Pakete.

```{r Pakete}
if(!require("pacman")) {install.packages("pacman");library(pacman)}
p_load(tidyverse, ggplot2, haven, mosaic, knitr,effectsize, car, broom, univOutl) # <1>

theme_set(theme_classic()) # <2>
options(scipen = 999) #<3>
```

1.  Mittels p_load laden wir alle ben√∂tigten Pakete gleichzeitig.
2.  Wir legen allgemein den Hintergrund theme_classic fest.
3.  Sorgt daf√ºr, dass sehr kleine Zahlen ausgeschrieben werden.

Anschlie√üend laden wir die Daten aus dem Allbus:

```{r}
daten = haven::read_dta("Datensatz/Allbus_2021.dta")
```

Um mit dem Datensatz zu arbeiten ben√∂tigen wir einige grundlegende Schritte des Datenmanagements (ausf√ºhrliche Erkl√§rungen finden sich [hier](https://patrickzerrer.github.io/R_Hands_on_Book/Skript_3.3.html)). F√ºr unseren t-test f√ºr unabh√§ngige Stichproben m√∂chten wir uns anschauen, wie sich der Wohnort der Befragten auf ihr Vertrauen in die Bundesregierung auswirkt. Wir nutzen dazu die folgenden Variablen:

+---------------+----------------------------------+-------------------------------+
| Variable      | Beschreibung                     | Auspr√§gungen                  |
+:=============:+:================================:+:=============================:+
| eastwest      | Erhebungsgebiet West-Ost         | 1= Alte Bundesl√§nder (Westen) |
|               |                                  |                               |
|               |                                  | 2 = Neue Bundesl√§nder (Osten) |
+---------------+----------------------------------+-------------------------------+
| pt12          | Vertrauen in die Bundesregierung | -42 = Datenfehler             |
|               |                                  |                               |
|               |                                  | -11 = TNZ Split               |
|               |                                  |                               |
|               |                                  | -9 = Keine Angabe             |
|               |                                  |                               |
|               |                                  | 1 = Gar kein Vertrauen        |
|               |                                  |                               |
|               |                                  | ...                           |
|               |                                  |                               |
|               |                                  | 7 = Gro√ües Vertrauen          |
+---------------+----------------------------------+-------------------------------+

Innerhalb unseres Datenmanageements schlie√üen wir fehlerhafte und fehlende Werte der Variablen pt12 aus und benennen diese anschlie√üend um:

```{r}

daten <- daten %>%
  filter(., pt12 > 0) %>%  #<1>
  rename(., trustreg = pt12) %>%  #<2>
  mutate(trustreg = as.numeric(trustreg), #<3>
         eastwest = haven::as_factor(eastwest)) #<3>
```

1.  Wir schlie√üend fehlende Werte (siehe Tabelle oben aus). Da diese alle negativ sind, k√∂nnen wir einfach alle Werte kleiner als 0 ausschlie√üen.
2.  Hier benennen wir die Variablen anders um unsere weitere Arbeit zu vereinfachen.
3.  Wir bringen unsere Daten in das korrekte Format. F√ºr den t-Test muss die abh√§ngige Variable als Vektor vorliegen und die unabh√§ngige Variable als Faktor.

## Deskriptives der abh√§ngigen Variablen

Als ersten Schritt schauen wir uns die deskriptiven Statistiken unserer abh√§ngigen Variablen Vertrauen in die Regierung f√ºr die beiden Faktorstufen unserer unabh√§ngigen Variablen an.

```{r}
des_stat <- (favstats(trustreg ~ eastwest, data = daten))
rownames(des_stat) <- c("Alte Bundesl√§nder", "Neue Bundesl√§nder")
kable(des_stat[,2:10], digits = 2)
```

Anhand dieser deskriptiven Daten sehen wir, dass das Vertrauen in die Bundesregierung in den alten Bundesl√§ndern im Mittelwert von `4,15` st√§rker ausgepr√§gt ist als in den neuen Bundesl√§ndern (Mittelwert von `3,86`). Um zu pr√ºfen, ob dieser Unterschied der Mittelwerte statistisch signifikant ist, berechnen wir in einem zweiten Schritt die Teststatistik des t-tests. Zun√§chst m√ºssen wir jedoch pr√ºfen, ob unsere Daten f√ºr die Berechnung geeignet sind. Dazu f√ºhren wir eine Voraussetzungspr√ºfung durch.

## Voraussetzungspr√ºfung

Bei dem t-test handelt es sich um ein statistisches Verfahren. Um die G√ºte der Ergebnisse sicherzustellen m√ºssen dabei einige Voraussetzungen beachtet werden. Dies sind im √úberblick:

-   die Unabh√§ngigkeit der Messung (siehe oben)
-   die korrekte Skalierung der UV (=Faktor) und AV (=numerisch)
-   keine extremen Ausrei√üer
-   die Normalverteilung der abh√§ngigen Variablen
-   die Varianzhomogenit√§t

### Skalierung der UV und AV

Die abh√§ngige Variable muss als numerischer Vektor vorliegen, die unabh√§ngige Variable wiederum als Faktor (mit zwei Auspr√§gungen). Die korrekte Skalierung der Variablen haben wir bereits innerhalb des Data Managements sichergestellt, k√∂nnen uns aber zus√§tzlich mit dem Befehl class noch einmal einen √úberblick √ºber das Skalenniveau unserer Variablen verschaffen.

```{r}
daten %>%  
  select(eastwest, trustreg) %>%  
  lapply(class)
```

### keine extremen Ausrei√üer

Da Ausrei√üer sich stark auf die Berechnung von Mittelwerten auswirken k√∂nnen, sollten m√∂glichst keine extremen Ausrei√üer innerhalb unserer zu testenden Variablen vorliegen. Es gibt verschiedene Methoden um Ausrei√üer zu bestimmen [siehe hier](https://statistikguru.de/r/ungepaarter-t-test-r/ausreisser-finden-7.html), wir nutzen im vorliegenden Fall die Tukey-Fence Methoden (Tukey, 1977), die jene F√§lle als Ausrei√üer ermitteln, die um den 1.5 fachen Interquartilsabstand von Q1 und Q3 entfernt liegen.

```{r}
daten %>% 
    filter(eastwest == "NEUE BUNDESLAENDER") %>% #<1>
    pull(trustreg) %>% #<2>
    LocScaleB(., method = "IQR") #<3>

daten %>% 
    filter(eastwest == "ALTE BUNDESLAENDER") %>% #<1>
    pull(trustreg) %>% #<2>
    LocScaleB(., method = "IQR") #<3>
```

1.  Wir filtern unsere Daten, sodass wir jeweils die Ausrei√üer f√ºr unsere beiden zu vergleichenden Gruppen angezeigt bekommen.
2.  Wir nutzen `pull` um die Ausrei√üer nur f√ºr die Spalte `trustreg` zu berechnen. Pull ist vergleichbar mit dem \$-Zeichen zur Variablenauswahl.
3.  Wir nutzen den Befehl `LocScaleB` aus dem Package `univOutl`. Innerhalb des Befehls, geben wir an, dass die Berechnung der Ausrei√üer anhand des Interquartilsabstandes (`method = "IQR"`) erfolgen soll.

Innerhalb unserer Daten finden sich f√ºr beide Gruppen (Alte und Neue Bundesl√§nder) keine Ausrei√üer in den Daten. Falls wir Ausrei√üer in den Daten h√§tten, m√ºssten wir uns diese Datenpunkte genauer ansehen und anschlie√üend entscheiden, ob wir diese aus unserer Analyse ausschlie√üen m√∂chten (mehr dazu findet sich [hier](https://statistikguru.de/r/ungepaarter-t-test-r/umgang-mit-ausreissern-2.html)). Grunds√§tzlich empfiehlt es sich, Ausrei√üer nur dann auszuschlie√üend, wenn diese logisch nicht m√∂glich sind (beispielsweise eine Mediennutzung eines Mediums von 30 Stunden pro Tag oder eine Altersangabe von 330).

### Normalverteilung der AV

Eine weitere wichtige, leicht vorab zu pr√ºfende Bedingung, die f√ºr einen Mittelwertvergleich mittels t-test erf√ºllt sein muss, ist die Normalverteilung der abh√§ngigen Variable. Diese k√∂nnen wir graphisch √ºberpr√ºfen:

```{r}
ggplot(daten, aes(trustreg)) + #<1>
  geom_histogram(aes(y = after_stat(count)), #<2>
                 color = "black", fill = "grey", 
                 binwidth = 1) + #<3>
  labs(x = "Vertrauen in die Bundesregierung", #<4>
         y = "")
```

1.  In R nutzen wir das Paket `ggplot2` von Wickham et al. um ein Histogramm auszugeben. Zun√§chst m√ºssen wir hier das Paket `ggplot2` mit dem Befehl `ggplot()` aufrufen. Anschlie√üend spezifizieren wir innerhalb der Klammer unseren Datensatz (hier `daten`) und unter aes unsere Variable (hier `trustgreg`).
2.  Die Spezifizierungen innerhalb der Klammern unseres Histogramms geben an, dass dieses auf den Zahlen unseres Datensatzes beruhen soll `(aes(y = after_stat(count))`, wir die Au√üenumrandung schwarz `color = black` und die F√ºllfarbe grau w√ºnschen (`fill = grey`). Diese Spezifikationen sind optional, sorgen jedoch f√ºr ein sch√∂neres Aussehen unserer Grafik.
3.  Mit `binwidth = 1` verweisen wir hier auf die Breite der Balken unseres Histogramms.
4.  F√ºr ein versch√∂nertes Aussehen unseres Graphen nutzen wir den Befehl `labs` um zus√§tzlich die Achsen zu beschriften.

Wir sehen anhand der Grafik, dass das Vertrauen in die Bundesregierung leicht rechtssteil ist, also die Teilnehmer grunds√§tzlich ein h√∂heres Vertrauen in die Bundesregierung angeben.

Zus√§tzliche Gewissheit bez√ºglich des Vorliegens der Normalverteilung bietet der *Kolmogorov-Smirnov-Test* oder der *Shapiro-Wilk-Test* (welcher f√ºr kleinere Stichproben zwischen 3 und 5000 F√§llen konzipiert ist). In R erhalten wir diese Tests mit dem Befehl `LillieTest()` aus dem Paket `DescTools()` bzw. `shapiro.test()`. Beide Tests testen auf Abweichung von der Normalverteilung, demnach sollte diese nicht signifikant ausfallen (da ein signifikanter Test aussagt, dass eine Abweichung von der Normalverteilung besteht, was wir nicht m√∂chten).

```{r}
daten  %>%  
  do(tidy(shapiro.test(.$trustreg)))
```

Im vorliegenden Beispiel ist der Shapiro-Tests signifikant. Allerdings reagiert der Test insbesondere bei gro√üen Stichproben sehr sensibel, sodass bereits leichte Abweichungen von der Normalverteilung (etwa durch Ausrei√üer) die Tests signifikant werden lassen; in diesen F√§llen ist es sinnvoll eher auf die graphische √úberpr√ºfung (siehe oben) zu schauen. Hier sehen wir, dass die Normalverteilung nicht drastisch verletzt ist. Grunds√§tzlich ist der t-Test auch recht robust bez√ºglich Abweichungen von der Normalverteilung. Alternativ k√∂nnen [Nicht-parametrische Testverfahren] genutzt werden.

### Varianzhomogenit√§t

Die letzte Voraussetzung, die erf√ºllt sein muss, ist die Homogenit√§t der Fehlervarianzen. Um diese zu testen, nutzen wir den Levene-Test.

```{r}
daten %>%  
  drop_na(eastwest, trustreg) %>% #<1>
  leveneTest(trustreg~eastwest, data = .) #<2>
```

1.  Wir schlie√üen fehlende Werte f√ºr die unabh√§ngige und abh√§ngige Variable aus.
2.  Innerhalb der Klammer m√ºssen wir zun√§chst unsere abh√§ngige Variable angeben. Danach folgt eine Tilde (\~). Im Anschluss m√ºssen wir unsere unabh√§ngige(n) Variablen angeben. Die Tilde sagt quasi, dass unsere abh√§ngige Variable durch unsere unabh√§ngigen Variablen bestimmt wird. Haben wir nur eine abh√§ngige Variable, so geben wir diese an.

Wenn der Levene-Test statistisch signifikant ausf√§llt, sollte die Hypothese homogener Varianzen abgelehnt werden. Falls der Test wie im vorliegenden Fall signifikant ausf√§llt (da der `Pr(>F-Wert)` kleiner als 0.05 ist) wurde die Voraussetzung der Homogenit√§t der Fehlervarianzen verletzt. In einem solchen Fall k√∂nnen wir wahlweise auf [Nicht-parametrische Testverfahren] ausweichen.

## Durchf√ºhrung des t-Tests

Bevor wir uns den nicht-parametrischen Testverfahren zuwenden, schauen wir uns zun√§chst die Durchf√ºhrung des parametrischen Student's t-Tests an. Diesen nutzen wir, wenn alle Voraussetzungen innerhalb der Voraussetzungspr√ºfung erf√ºllt sind (wenngleich man wahlweise auch direkt standardm√§√üig den Welch-Test (siehe [Nicht-parametrische Testverfahren] nutzen kann). Dazu nutzen wir den Befehl `t.test` aus dem Paket `mosaic`.

```{r}
daten %>% 
  drop_na(eastwest, trustreg) %>% #<1>
  mosaic::t.test(trustreg ~ eastwest, #<2>
         alternative = "two.sided",  #<3> 
         var.equal = T, #<4>
         data = .)
```

1. Ausschlie√üen von fehlenden Daten. 
2. Durchf√ºhrung des t-Tests mittels der Funktion `t.test` aus dem `mosaic`-Package.
3. Als Alternative verwenden wir hier `two.sided`, da wir zweiseitig testen. Wenn wir innerhalb unserer Hypothese eine klare Aussage bez√ºglich der Richtung des t-Testes machen, k√∂nnen wir auch einseitig testen. In diesem Fall w√ºrden wir `"less"` oder `"greater"` verwenden.  
4. Wenn wir Varianzhomogenit√§t annehmen (siehe Levene-Test der Voraussetzungspr√ºfung), verwenden wir hier var.equal = T. Alternativ k√∂nnen wir den nicht-parametrischen Welch-Test rechnen (siehe nicht-parametrische Testverfahren), welche in R die default-Einstellung darstellt.    

In einem zweiten Schritt m√ºssen wir zus√§tzlich die Effektst√§rke *cohens' d* (Cohen, 1992) berechnen. Der t-Test selbst gibt uns eine Aussage √ºber die Signifikanz der Ergebnisse, also wie wahrscheinlich es ist, dass der von uns gefundene Effekt nicht zuf√§llig ist. Cohen's d wiederum macht eine Aussage zur Effektstr√§rke, also wie stark ein signifikanter Mittelwertunterschied ist. Dazu nutzen wir die Funktion `cohens_d` aus dem Paket `effectsize`. 

```{r}
daten %>% 
  drop_na(eastwest, trustreg) %>%  #<1>
  cohens_d(trustreg~eastwest, data = .) # <2>
```

1. Ausschlie√üen von fehlenden Daten. 
2. Ausgeben der Effektst√§rke nach Cohen (1992)

## Interpretation des Outputs

Innerhalb des Outputs des t-tests erhalten wir die Teststatistik (`t`), die Freiheitsgrade (`df`), das Signifikanzniveau (`p-value`), das 95% Konfidenzintervall, sowie die Mittelwerte unserer beiden Vergleichsgruppen. Insbesondere interessiert uns in diesem Fall der Signifikanzwert (`p-Value`). Wenn dieser, wie in unserem Fall unter 0.05 liegt, ist der t-Test signifikant, dass bedeutet, dass die gefunden Mittelwertunterschiede mit 95% Wahrscheinlichkeit nicht zuf√§llig sind. 

Bez√ºglich der Interpretation der Effektst√§rke gilt nach Cohen (1992):

| Cohen's d  | Effektst√§rke                    |
|------------|---------------------------------|
| 0 - 0.19   | kein, bzw. sehr geringer Effekt |
| 0.2 - 0.49 | geringer Effekt                 |
| 0.5 - 0.79 | mittlerer Effekt                |
| gr√∂√üer 0.8 | starker Effekt                  |

In unserem Fall haben wir eine Effektst√§rke von 0.18. Demnach ist der gefundene Effekt zwar signifikant, aber weist keine bzw. nur eine sehr geringe Effektst√§rke auf. 

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse des t-tests werden √ºblicherweise im Text angegeben. F√ºr diese Angabe werden die folgenden Informationen ben√∂tigt:

‚úÖ die Mittelwerte und Standardabweichung der einzelnen Vergleichsgruppen

‚úÖ der df-Wert

‚úÖ der  t-Wert

‚úÖ der p-Wert

‚úÖ die Effektgr√∂√üe

Das Format ist √ºblicherweise:

> ***Beispiel:*** Personen mit Lebenswohnsitz in den alten Bundesl√§ndern (*M = 4.15;SD=1.58*) besitzen ein h√∂heres Vertrauen in die Bundesregierung als Personen mit Lebenswohnsitz in den neuen Bundesl√§ndern (*M = 3.86;SD=1.71*). Ein Student's T-Test zeigt, dass der Lebenwohnsitz einen signifikanten Einfluss auf das Vertrauen in Bundesregierung hat *t(3516)= 4.9349, p\<0,001*. Die Effektst√§rke nach Cohen (1992) weist jedoch mit *d = 0,18* auf einen nicht vorhanden, bzw. nur sehr geringen Effekt hin.

:::

## Nicht-parametrische Testverfahren 

Wenn einzelne Voraussetzungen verletzt wurden (siehe oben), k√∂nnen statt dem normalen t-test nicht-parametrische Testverfahren verwendet werden. 

Das gel√§ufigste Testverfahren ist der Welch-Test, welcher in R das standardm√§√üige Testverfahren darstellt. Der Welch-Test ist robust gegen√ºber Verletzungen der Varianzhomogenit√§t sowie der Normalverteilung (Rasch et al., 2011), sodass dieser Test auch bei nicht-idealen Daten gerechnet werden kann. Verschiedene [Autoren](https://statistikguru.de/r/ungepaarter-t-test-r/t-test-oder-welch-test.html) empfehlen den Test sogar standardm√§√üig immer zu berechnen, da der Test auch bei homogenen Varianzen der Daten eingesetzt werden kann. Den Welch-Test k√∂nnen wir in R √ºber die bereits bekannte Funktion t.test aufrufen. Wir m√ºssen lediglich bei dem Zusatz `var.equal = T` zu `var.equal = F` √§ndern. Alternativ k√∂nnen wir den Zusatz auch einfach weglassen, da innerhalb des mosaic-Packages standardm√§√üig der Welch-Test gerechnet wird.

```{r}
daten %>% 
  drop_na(eastwest, trustreg) %>%
  mosaic::t.test(trustreg ~ eastwest, 
         alternative = "two.sided", 
         var.equal = F, #<1>
         data = .)
```
1. F√ºr den Welch-Test m√ºssen wir lediglich den Zusatz `var.equal` auf `F` oder `FALSE` setzen. 

Anschlie√üend m√ºssen wir erneut die Effektst√§rke berechnen, wobei wir hier ebenfalls durch den Zusatz `var.equal= F` angeben, dass unsere Fehlervarianzen nicht homogen sind:

```{r}
daten %>% 
  drop_na(eastwest, trustreg) %>%  #<1>
  effectsize::cohens_d(trustreg~eastwest, data = ., var.equal = F) # <2>
```
Die Ergebnisse zeigen, dass unser Test weiterhin signifikant ist, allerdings die Effektst√§rke noch ein wenig schlechter geworden ist. Die Ergebnisse geben wir genauso wie die Ergebnisse des normalen Student's T-Test an (siehe oben), wobei wir im Text darauf verweisen, dass wir aufgrund der Verletzungen der Voraussetzungen einen nicht-parametrischen Welch-Test gerechnet haben. Zudem ist es sinnvoll, bei Verletzungen der Normalverteilung statt dem Mittelwert den Median anzugeben. 

Alternativ zum Welch-Test gibt es noch den Mann-Whitney-U Test bzw. den Wilcoxon-Rangsummentest. Beide Verfahren testen fast dasselbe  (zur Historie der Testverfahren siehe [hier](http://www.regorz-statistik.de/inhalte/tutorial_wilcoxon_mann_whitney_u_test.html)) und k√∂nnen angewandt werden, wenn die Voraussetzung der Normalverteilung verletzt wurde. Da die Testverfahren jedoch von etwas anderen Hypothesen ausgehen und der Welch-Test ebenfalls robust gegen√ºber der Verletzung der Normalverteilung (bei Gruppen ab ca. n=30) ist, empfiehlt sich hier der Welch-Test.  


# t-Test f√ºr unabh√§ngige Stichproben

Der t-Test f√ºr verbundene bzw. abh√§ngige Stichproben pr√ºft, ob zu zwei unterschiedlichen Zeitpunkten signifikante Mittelwertunterschiede bestehen. Anhand dieses Datensatzes k√∂nnen wir den t-Test f√ºr verbundene Stichproben nicht durchf√ºhren, daher gehen wir an dieser Stelle nicht n√§her auf das Verfahren ein. Ein Beispiel sowie weitere Infos zur Durchf√ºhrung des Tests findet ihr bei [Bj√∂rn Walther](https://bjoernwalther.com/t-test-fuer-abhaengige-stichproben-in-r-rechnen-und-interpretieren/) sowie [Statistik Guru](https://statistikguru.de/r/gepaarter-t-test-r/gepaarter-t-test-in-r.html). Die nicht-parametrische Alternative des Tests ist der Wilcoxon-Vorzeichen-Rangtest.

# t-Test f√ºr Einstichproben

Beim t-Test f√ºr Einstichproben testen wir, ob die Werte unserer Stichprobe einem vorab festgelegten Wert entsprechen. So k√∂nnen wir beispielsweise mit Blick auf das Einkommen schauen, ob das monatliche Nettoeinkommen aus unserer Stichprobe dem Bundesdurchschnitt im Jahr 2021 entspricht. Gem√§√ü dem [statistischen Bundestamt](https://de.statista.com/statistik/daten/studie/74510/umfrage/nettogehalt-im-jahr-je-arbeitnehmer-in-deutschland/) betrug das Nettoeinkommen in Deutschland im Jahr 2020 2.165 Euro pro Monat (25.980 Euro pro Jahr). Dies ist demnach unser Testwert gegen den wir testen.

## Data Management

Innerhalb des Datamanagements benennen wir zun√§chst die entsprechende Variable aus den Allbus-Daten in `einkommen` um und filtern fehlende Werte hinaus.

```{r}
daten_one <- daten %>% 
  filter(., di01a > 0) %>% 
  rename(., einkommen = di01a)
```

## Voraussetzungspr√ºfung

Der Einstichprobentest setzt √§hnlich wie der two-sided und paired test eine Normalverteilung der abh√§ngigen Variablen voraus. Diese k√∂nnen wir erneut mit dem Shapiro-Wilk-Test √ºberpr√ºfen:

```{r}
daten_one  %>%  
  do(tidy(shapiro.test(.$einkommen)))
```

Da unser Ergebnis signifikant ausf√§llt, m√ºssen wir hier leider die Normalverteilung unserer AV ablehnen (wir testen ja auf signifikante Abweichung von der Normalverteilung, daher m√∂chten wir bei diesem Test nicht ein signifikantes Ergebnis haben). Um weitere Gewissheit zu erlangen, pr√ºfen wir die Normalverteilung zus√§tzlich optisch mit einem Histogramm:

```{r}
ggplot(daten_one, aes(einkommen)) + #<1>
  geom_histogram(aes(y = after_stat(count)), #<2>
                 color = "black", fill = "grey", 
                 binwidth = 500) + #<3>
  labs(x = "Netto-Monatseinkommen", #<4>
         y = "")
```

1.  In R nutzen wir das Paket `ggplot2` von Wickham et al. um ein Histogramm auszugeben. Zun√§chst m√ºssen wir hier das Paket `ggplot2` mit dem Befehl `ggplot()` aufrufen. Anschlie√üend spezifizieren wir innerhalb der Klammer unseren Datensatz (hier `daten_one`) und unter aes unsere Variable (hier `einkommen`).
2.  Die Spezifizierungen innerhalb der Klammern unseres Histogramms geben an, dass dieses auf den Zahlen unseres Datensatzes beruhen soll `(aes(y = after_stat(count))`, wir die Au√üenumrandung schwarz `color = black` und die F√ºllfarbe grau w√ºnschen (`fill = grey`). Diese Spezifikationen sind optional, sorgen jedoch f√ºr ein sch√∂neres Aussehen unserer Grafik.
3.  Mit `binwidth = 500` verweisen wir hier auf die Breite der Balken unseres Histogramms.
4.  F√ºr ein versch√∂nertes Aussehen unseres Graphen nutzen wir den Befehl `labs` um zus√§tzlich die Achsen zu beschriften.

Die Grafik verst√§rkt die Einsch√§tzung des Shapiro-Wilk-Tests, dass keine Normalverteilung vorliegt. In einem solchen Fall w√ºrden wir auf den nicht-parametrische one-sample Wilcoxon-Test ausweichen. Der Vollst√§ndigkeit halber f√ºhren wir nachfolgend dennoch beide Testverfahren auf.

## Durchf√ºhrung des t-tests f√ºr Einstichproben

Wie bereits zuvor aufgef√ºhrt liegt das monatliche Nettoeinkommen laut [Statista](https://de.statista.com/statistik/daten/studie/74510/umfrage/nettogehalt-im-jahr-je-arbeitnehmer-in-deutschland/) bei 2165 Euro. Innerhalb der bekannten Funktion t-test geben wir diesen Wert als den "wahren Wert" des Mittelwertes mit dem Zusatz `mu=2.165` an

```{r}
t.test(daten_one$einkommen , mu = 2165)
```

```{r}
cohens_d(daten_one$einkommen, data = daten, mu = 2165)
```

## Interpretation des Outputs

Innerhalb des Output des one-sample-t-Testes erhalten wir die Teststatistik (`t`), die Freiheitsgrade(`df`), den Signifikanzwert (`p-value`) sowie das 95% Konfidenzintervall des wahren Wertes und den Mittelwert unserer Stichprobe (`mean of x`).

Grunds√§tzlich interessiert uns bei einem Blick auf den Output vor Allem der p-value. Wenn dieser unter 0,05 liegt, ist unser Test signifikant. Im vorliegenden Fall ist der Test mit `p < .000` signifikant, dies bedeutet unsere Stichprobe weicht signifikant von unserem vorab definierten Vergleichswert ab. Dementsprechend ist der Mittelwert des Nettoeinkommens unserer Stichprobe signifikant h√∂her (siehe `mean of x`) als unser Vergleichswert.

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse des Einstichproben-t-tests werden √ºblicherweise in Textform angegeben. F√ºr diese Angabe werden die folgenden Informationen ben√∂tigt:

‚úÖ der df-Wert

‚úÖ der t-Wert

‚úÖ der p-Wert

‚úÖ der d-Wert

Das Format ist √ºblicherweise:

> Das Nettoeinkommen innerhalb unserer Stichprobe (*M* = 2455.025) ist signifikant h√∂her (*p* \< .000) als der Vergleichswert von 2165, welcher das Durchschnittsnettoeinkommen der deutschen Bev√∂lkerung repr√§sentiert, *t(795) = 5,102*. Nach Cohen (1992) handelt es sich jedoch um keinen bzw. einen nur sehr geringen Effekt (*d* = 0,18).
:::

## Nicht-parametrischer Test: one sample Wilcoxon Test

Wenn die Voraussetzung der Normalverteilung nicht gegeben ist ([siehe hier](https://patrickzerrer.github.io/R_Hands_on_Book/Skript_6.3.html#voraussetzungspr%C3%BCfung-2)) k√∂nnen wir statt dem normalen Einstichproben-t-Test den one sample Wilcoxon Test berechnen. Auch bei diesem geben wir mit dem Zusatz `mu=` den Wert an, gegen welchen wir testen m√∂chten.

```{r}
wilcox.test(daten_one$einkommen, mu = 2165)
```

Als Output erhalten wir lediglich die Teststatistik (`V`) und den Signifikanz-Wert (`p-value`). Interessanterweise ist der nicht-parametrische Wilcoxon-Test im Gegensatz zum parametrischen Test nicht signifikant (p-value √ºber 0.05). Da unsere voraussetzungspr√ºfung darauf hindeutet, dass die Daten nicht normalverteilt sind, w√ºrden wir in diesem Fall dem nicht-parametrischen Wilcoxon-Test folgen. Dementsprechend findet sich kein signifikanter Unterschied zwischen unserer Stichprobe und dem deutschen Durchschnittseinkommen.

> Der Wilcoxon signed rank Test zeigt, dass das Nettoeinkommen innerhalb unserer Stichprobe (*Median* = `r median(daten_one$einkommen)`) nicht signifikant h√∂her als der Vergleichswert von 2165, welcher das Durchschnittsnettoeinkommen der deutschen Bev√∂lkerung repr√§sentiert, *V = 170966*, *p = .05*.

## Literatur

::: callout-note
## Literatur und Beispiele aus der Praxis

Cohen, J. (1992). A power primer. Psychological bulletin, 112(1), 155-159.

Rasch, D., Kubinger, K. D., & Moder, K. (2011). The two-sample t test: pre-testing its assumptions does not pay off. Statistical papers, 52, 219-231

Wir empfehlen euch folgende Lehrb√ºcher und Online-Materialien, falls ihr weiterf√ºhrende Informationen braucht.

> üìñ Gehrau, V., Maubach, K., & Fujarski, S. (2022). Einfache Datenauswertung mit R. [Link](https://link.springer.com/book/10.1007/978-3-658-34285-2)

> üìñ StatistikGuru (2023). Gepaarter t-Test in R [Link](https://statistikguru.de/r/gepaarter-t-test-r/gepaarter-t-test-in-r.html)

> üìñ Walther, B. (2022). t-Test f√ºr abh√§ngige Stichproben in R rechnen und interpretieren [Link](https://bjoernwalther.com/t-test-fuer-abhaengige-stichproben-in-r-rechnen-und-interpretieren/)

> üìñ Masch, L., Kieslich, K., Huseljiƒá, K., W√§hner, M., & Neef, J.-S. (2021). R - Ein Einf√ºhrungsskript [Link](https://docserv.uni-duesseldorf.de/servlets/DerivateServlet/Derivate-62343/R-Eine%20Einf%C3%BCrungsskript.pdf)

> üìñ Field, Z., Miles, J., & Field, A. (2012). Discovering statistics using R. Discovering statistics using r, 1-992. [Link](https://suche.suub.uni-bremen.de/peid=B68436977&LAN=DE&CID=7699632&index=L&Hitnr=1&dtyp=D&rtyp=a&Exemplar=1)
:::
