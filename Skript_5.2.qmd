---
title: "Die Faktorenanalyse"
author: "Patrick Zerrer"
toc: true
number-sections: true
highlight-style: pygments
format:
  html:
    code-fold: false
    code-line-numbers: true
---

![Betreten der zugrunde liegenden Struktur der Stadt, Bild generiert von Midjourney](Bilder/zemkipatrick_comic_style_walking_down_the_stairs_and_entering_t_191dbce1-eeb0-4ac5-8a31-497d40f45b11.png)

# Durchf√ºhren einer Faktorenanalyse in R

Wir m√∂chten - wie bereits in Kaptitel 5.1 angesprochen - ein Index f√ºr die von uns angenommene latente Variable *Vertrauen in gesellschaftliche Institutionen* bilden. An dieser Stelle m√ºssten wir uns zun√§chst Gedanken √ºber das Konstrukt *Vertrauen in gesellschaftliche Institutionen* machen und eine theoretische Grundlage entwickeln. Wir k√ºrzen diesen Prozess an dieser Stelle etwas ab und m√∂chten die lesende Person ermutigen einen kurzen Blick in den Aufsatz von [Nina Steindl](https://link.springer.com/content/pdf/10.1007/978-3-658-27910-3_7.pdf) aus dem Jahr 2019 zum *Vertrauen in gesellschaftliche Institutionen* von Journalist:innen zu werfen. Wenn wir eine theoretische Vorstellung entwickelt haben, k√∂nnen wir mit der empirische √úberpr√ºfung der latenten Variable mittels explorativer Faktorenanalyse starten.

Die explorative Faktorenanalyse (EFA) ist eine statistischen Methoden, die dazu dient, die kleinste Anzahl hypothetischer Konstrukte (auch als Faktoren, Dimensionen, latente Variablen bezeichnet) zu ermitteln. Indem die beobachtete Kovarianz zwischen einer Reihe von Messvariablen (auch als beobachtete Variablen oder Indikatoren bezeichnet) erkl√§rt wird. Konkret sollen die gemeinsamen Faktoren ermittelt werden, die die Struktur zwischen den gemessenen Variablen erkl√§ren. Wobei wir in den Sozialwissenschaften davon ausgehen, dass es sich bei diesen Faktoren um unbeobachtbare Merkmale - also *latente Variablen* - handelt.

> *Ein Faktor ist eine unbeobachtbare Variable, die mehr als eine beobachtete Messgr√∂√üe beeinflusst und f√ºr die Korrelationen zwischen diesen beobachteten Messgr√∂√üen verantwortlich ist. Mit anderen Worten, die beobachteten Ma√üe stehen in Beziehung zueinander, weil sie eine gemeinsame Ursache haben (d. h. sie werden von demselben zugrunde liegenden Konstrukt beeinflusst); wenn das latente Konstrukt abgetrennt wurde, sind die Interkorrelationen zwischen den beobachteten Ma√üen gleich Null.* [(Brown, 2015: 10)](https://journals.sagepub.com/doi/10.1177/0095798418771807)

In unserem Fall interessiert uns die latente Variable *Vertrauen in gesellschaftliche Institutionen*. Wir m√∂chten Wissen, ob wir diese latente Variable bzw. diesen Faktor aus den einzelenen Indikatoren (den Fragen aus dem Allbus-Fragebogen) ableiten k√∂nnen. Konkret m√ºssen wir √ºberpr√ºfen, ob sich die theoretisch angenommene *latenten Variable* auch in den Daten zu finden ist. Hierf√ºr k√∂nnen wir die Faktorenanalyse oder Principal Component Analysis (PCA) verwenden.

Wir beginnen zun√§chst mit der Vorbereitung und Laden die notwendigen Pakete.

```{r Pakete}
if(!require("pacman")) {install.packages("pacman");library(pacman)}
p_load(tidyverse, ggplot2, haven, psych, psy, nFactors, htmlTable)
```

Danach laden wir die Daten aus dem Allbus.

```{r Laden der Daten}
daten = haven::read_dta("Datensatz/Allbus_2021.dta")
```

## Teildatensatz mit den ben√∂tigten Variablen

Die Variablen werden aufgrund ihrer N√ºtzlichkeit als Indikatoren f√ºr die zu untersuchende latente Variable ausgew√§hlt. Entsprechend ist es wichtig, dass die Variablen [inhaltliche](https://dorsch.hogrefe.com/stichwort/validitaet-inhaltliche#search=59c61a28aad6ded0422fcadcc4bb8963&offset=0), [diskriminante](https://dorsch.hogrefe.com/stichwort/validitaet-diskriminante#search=bc41d30195bf495e7ff27be31e40a75c&offset=0) und [konvergente](https://dorsch.hogrefe.com/stichwort/validitaet-konvergente) Validit√§t aufweisen. Etwas vereinfacht ausgedr√ºckt sollten die Indikatoren √ºber eine inhaltliche Passung zur latenten Variable verf√ºgen, m√∂glichst gut von anderen latenten Variablen abgrenzbar und mit mehreren unterschiedlichen Arten der Messung nachweisbar sein.

In unserem Fall m√∂chten wir das *Vertrauen in gesellschaftliche Institutionen* untersuchen, entsprechend sollten wir Variablen bzw. Indikatoren ausw√§hlen, die die unterschiedlichen Bestandteile der latenten Variable abdecken.

Ganz konkret w√§hlen wir Variablen aus, die das...

* *Vertrauen in das Gesundheitswesen* (pt01)
* *Vertrauen in das Bundesverfassungsgericht* (pt02)
* *Vertrauen in den Bundestag* (pt03)
* *Vertrauen in die Stadt- oder Gemeindeverwaltung* (pt04)
* *Vertrauen in die Katholische Kirche* (pt06)
* *Vertrauen in die Evangelische Kirche* (pt07)
* *Vertrauen in die Justiz* (pt08)
* *Vertrauen in das Fernsehen* (pt09)
* *Vertrauen in das Zeitungswesen* (pt10)
* *Vertrauen in die Hochschulen* (pt11)
* *Vertrauen in die Bundesregierung* (pt12)
* *Vertrauen in die Polizei* (pt14)
* *Vertrauen in die Politischen Parteien* (pt15)
* *Vertrauen in die Kommission der EU* (pt19)
* *Vertrauen in das Europ√§ische Parlament* (pt20)


... erfassen.

F√ºr die statistische Identifizierung einer latenten Variablen bzw. eines Faktors werden mindestens drei gemessene Variablen ben√∂tigt, obwohl mehr Indikatoren vorzuziehen sind. Es werden beispielsweise auch vier bis sechs Indikatoren pro Faktor empfohlen. Im Allgemeinen funktioniert die EFA besser, wenn jeder Faktor √ºberdeterminiert ist (d. h. es werden mehrere gemessene Variablen von der zu entdeckenden latenten Variable bzw. Faktor beeinflusst). Unabh√§ngig von der Anzahl sollten Variablen, die voneinander abh√§ngig sind, nicht in eine EFA einbezogen werden.

```{r Teildatensatz}
allbus_vertrauen = daten %>%
  
  # Wir w√§hlen mit select() die gew√ºnschten Variablen aus
  select(pt01:pt20) %>% 
  
  # die Kombination aus mutate() und across() erm√∂glicht es uns die Funktion as.numeric() in einer Zeile auf alle zuvor ausgew√§hlten Variablen anzuwenden
  mutate(across(pt01:pt20, ~ as.numeric(.))) %>% 

  # Wir codieren die unterschiedlichen fehlenden Werte um (aus der Allbus-Dokumentation entnommen)
  mutate(across(pt01:pt20, ~ ifelse(.%in% c(-9, -11, -42), NA,.))) %>% 
  
  # Wir schmei√üen fehlende Werte raus
  na.omit()
```

Wir bennen die ausgew√§hlten Indikatoren um, damit die Bezeichnungen der Indikatoren f√ºr uns leichter zu merken sind. 

```{r Rename}
allbus_vertrauen = allbus_vertrauen %>% 
  
  # mit dem rename() Befehl k√∂nnen wir die Variablen umbennen
  rename(Ver_Gesundheitswesen = pt01,
         Ver_BVerfG = pt02,
         Ver_Bundestag = pt03,
         Ver_Verwaltung = pt04,
         Ver_kath_Kirche = pt06,
         Ver_evan_Kirche = pt07,
         Ver_Justiz = pt08,
         Ver_TV = pt09,
         Ver_Zeitung = pt10,
         Ver_Uni = pt11,
         Ver_Regierung = pt12,
         Ver_Polizei = pt14,
         Ver_Parteien = pt15,
         Ver_Kom_EU = pt19,
         Ver_EU_Par = pt20)

# Wir √ºberpr√ºfen kurz, ob die Umbenennung geklappt hat und lassen uns die ersten Zeilen des Datensatzes anzeigen
htmlTable(head(allbus_vertrauen))
```


Neben der Auswahl der Variablen bzw. Indikatoren m√ºssen auch die F√§lle (in unserem Fall die Anzahl der befragten Personen) festgelegt werden. Hier sollten wir uns zun√§chst fragen, ob die Stichprobe der Teilnehmer:innen in Bezug auf die gemessenen Indikatoren sinnvoll ist? Handelt es sich um eine repr√§sentative Stichprobe? Bei dem Allbus ist das der Fall und entsprechend k√∂nnen wir davon ausgehen, dass wir eine passende Stichprobe f√ºr die Durchf√ºhrung eine EFA vorliegen haben.

## Deskriptive Statistik f√ºr den Teildatensatz

Wir werfen einen kurzen Blick in die deskriptive Statistik f√ºr unseren Teildatensatz, um ein besseres Verst√§ndnis f√ºr die Daten zu erhalten.

```{r Deskriptive Statistik}
summary(allbus_vertrauen)
```

## Suche nach der zugrunde liegenden Variable - Die Faktorenanalyse

Die Faktorenanalyse bringt, wie jedes statistische Verfahren, eine Reihe von Vorraussetzungen mit. Diese Vorraussetzungen sollten wir kennen und bei der Anwendung der Faktorenanalyse beachten. Viele der Vorraussetzungen beziehen sich auf Pearson-Korrelationskoeffizienten, welcher die statistsiche Grundlage f√ºr die Berechnung der Faktoren bildet.

* *Varianz*: Wir sollten sichergehen, dass die Daten aus unserer Stichprobe ausreichend varrieren. Wir werfen hierf√ºr ein Blick in die Daten.

```{r Varianz}
# Visuelle √úberpr√ºfung mit einem Histogram f√ºr die erste Variable "Ver_Gesundheitswesen". Die restlichen Variablen sollten auch √ºberpr√ºft werden.
colors = c(rep("darkgreen", 1))

ggplot(allbus_vertrauen, aes(x = Ver_Gesundheitswesen)) +
  geom_histogram(binwidth = 0.5, fill = colors) 
```


* *Linearit√§t*: Der Pearson-Korrelationskoeffizient (r) misst die lineare Beziehung zwischen zwei Variablen. Wenn die tats√§chliche Beziehung nicht linear ist, dann verringert sich der Wert von r. Wir k√∂nnen auf Linearit√§t u.a. visuell durch das Betrachten der Daten mittel Streudiagramm pr√ºfen.

```{r Linearit√§t}
# Visuelle √úberpr√ºfung mit einem Streudiagramm f√ºr die ersten beiden Variable (Ver_Gesundheitswesen und Ver_BVerfG)

ggplot(allbus_vertrauen, aes(x = Ver_Gesundheitswesen, y = Ver_BVerfG)) +
  geom_point() +
  geom_abline(linetype = "dashed", color = "darkgreen", size = 1)
```


* *Normalverteilung*: Der Pearson-Korrelationskoeffizient setzt eine Normalverteilung voraus. Allerdings finden sich in der Realit√§t fast nie perfekt normalverteilte Daten. Schiefe und Kurtosis sind besonders einflussreich die Ergebnisse der Faktorenanalyse und k√∂nnen im Extremfall artefaktische Ergenbnisse erzeugen. 

```{r Normalverteilung}
# Visuelle √úberpr√ºfung mit einem Histogram f√ºr die erste Variable (Ver_Gesundheitswesen)
colors = c(rep("darkgreen", 1))

ggplot(allbus_vertrauen, aes(x = Ver_Gesundheitswesen)) +
  geom_histogram(binwidth = 0.5, fill = colors) 

# Statistische √úberpr√ºfung mittels Shapiro Wilk Test f√ºr die erste Variable (pt01)
shapiro.test(allbus_vertrauen$Ver_Gesundheitswesen)

# Ein p-Wert unter 0.05 = keine Normalverteilung 
# Ein p-Wert √ºber 0.05 = Normalverteilung
```

* *Level der Messung*: Bei Pearson-Korrelationen wird davon ausgegangen, dass normalverteilte Variablen auf Intervall- oder Verh√§ltnisskalen gemessen werden, d. h. es handelt sich um kontinuierliche Daten mit gleichen Intervallen. Diese Eigenschaften treffen nicht auf ordinale (bspw. Kategorien) oder dochotome (bspw. Wahr-Falsch-Items) Variablen zu, was sich negativ auf Pearson-Korrelationskoeffizieten auswirkt und zu verzerrten Ergebnissen f√ºhren kann. Allerdings ist ein betr√§chtlicher Teil der Daten, mit denen wir zu tun haben, ordinal oder dichotom skaliert, um auch mit diesen Daten arbeiten zu k√∂nnen nutzen wir die polychorische Korrelation, welche robuster Nicht-Normalverteilung ist.

* *Fehlende Werte*: In jeder Studie sollten wir die Anzahl und die Art der fehlenden Werte sowie die Gr√ºnde und die Methoden f√ºr den Umgang mit diesen Daten angegeben werden. 

```{r fehlende Werte}
# Wir haben den Code bereits am Anfang ausgef√ºrht
allbus_vertrauen = allbus_vertrauen %>%  
  
  # Wir codieren die unterschiedlichen fehlenden Werte um (aus der Allbus-Dokumentation entnommen)
  mutate(across(Ver_Gesundheitswesen:Ver_EU_Par, ~ ifelse(.%in% c(-9, -11, -42), NA,.))) %>% 
  
  # Wir schmei√üen fehlende Werte raus
  na.omit()
```

* *Ausrei√üer / Outliers*: Wir sollten Ausrei√üer identifizieren und im Zweifel von der Analyse ausschlie√üen, da diese zu einer Verzerrung der Ergebnisse f√ºhren k√∂nnen. Zu den Methoden zur Erkennung von Ausrei√üern geh√∂ren Boxplots und Streudiagramme f√ºr einzelne Variablen sowie der Mahalanobis-Abstand f√ºr mehrere Variablen.

```{r Beispiel Boxplot}
boxplot(allbus_vertrauen)
```

* *Passung der Daten f√ºr die Faktorenanalyse*: Wir sollten trotz unserer guten Datengrundlage nochmals pr√ºfen, ob die gemessenen Variablen ausreichend miteinander korreliert sind, um eine Faktorenanalyse zu rechtfertigen. Eine Korrelation zwischen zwei Variablen gibt an, ob und wie stark ein Zusammenhang zwischen den beiden Variablen besteht. An dieser Stelle ist es wichtig, sich zu merken, dass eine Korrelation die St√§rke eines Zusammenhangs angibt. Eine genauere Erkl√§rung findet ihr im Kapitel 7. Zun√§chst k√∂nnen wir einen Blick in die Korrelationsmatrix werfen - eine betr√§chtliche Anzahl von Korrelationen sollte ¬±.30 √ºberschreiten. Alternativ k√∂nnen wir ein objektiveren Test der Faktorf√§higkeit der Korrelationsmatrix durchf√ºhren. Hierf√ºr greifen wir auf den Sph√§rizit√§tstest nach Bartlett (1954) zur√ºck.

```{r Beispiel f√ºr eine Korrelationsmatrix}
htmlTable(round(cor(allbus_vertrauen), digits = 3))
```

Noch zu pr√ºfen ist die Korrelation der Items miteinander, hierf√ºr nehmen wir den Bartlett Test.

```{r Bartlett-Test}
cortest.bartlett(allbus_vertrauen)
```

Bei gro√üen Stichprobenumf√§ngen, wie in unserem Fall mit dem Allbus, reagiert der Bartlett-Test selbst auf geringf√ºgige Abweichungen vom Zufallsprinzip empfindlich, so dass seine Ergebnisse durch ein Ma√ü f√ºr die Stichprobenad√§quanz erg√§nzt werden sollten. Das Kaiser-Meyer-Olkin (KMO; Kaiser, 1974) Ma√ü f√ºr die Stichprobenad√§quanz ist das Verh√§ltnis von Korrelationen und partiellen Korrelationen, das das Ausma√ü widerspiegelt, in dem Korrelationen eine Folge der √ºber alle Variablen geteilten Varianz sind und nicht der von bestimmten Variablenpaaren geteilten Varianz.

```{r KMO und MSA}
KMO(allbus_vertrauen)
```

KMO-Werte reichen von 0,00 bis 1,00 und k√∂nnen sowohl f√ºr die gesamte Korrelationsmatrix als auch f√ºr jede gemessene Variable berechnet werden. Insgesamt sind KMO-Werte ‚â•.70 erw√ºnscht und Werte unter .50 werden im Allgemeinen als inakzeptabel angesehen. In diesem Fall ist die Korrelationsmatrix nicht faktoriell. 

### Modell der Faktorenanalyse 

Wenn wir den Begriff Faktorenanalyse verwenden, meinen wir meistens zwei eigentlich unterschiedliche Verfahren, die sich in Zweck und Berechnung unterscheiden: die Hauptkomponentenanalyse (PCA) und die explorative Faktorenanalyse. Die Hauptkomponentenanalyse analysiert die gesamte Korrelationsmatrix und zielt darauf ab, Daten zu reduzieren und dabei so viele Informationen aus dem urspr√ºnglichen Datensatz wie m√∂glich zu erhalten. Zu diesem Zweck berechnet die Hauptkomponentenanalyse sogenannte Linearkombinationen der urspr√ºnglichen Messvariablen, die so viele Informationen wie m√∂glich erkl√§ren. Diese neuen Messvariablen werden als sogenannte Komponenten bezeichnet und sind im engeren Sinn keine latenten Konstrukte. 

Die Faktorenanalyse versucht im Unterschied dazu, die Gesamtvarianz der gemessenen Variablen in *gemeinsame* Varianz (Kommmunialit√§t oder h2) und die *einzigartige* Varianzen (u2) zu trennen. Dies geschieht indem eine reduzierte Korrelationsmatrix analysiert wird, bei der eine Sch√§tzung der gemeinsamen Varianz jeder Messvariablen auf der Diagonalen der Korrelationsmatrix platziert wird. 

Zusammenfassend liefern beide Methoden, also sowohl die PCA als auch die Faktorenanalyse eine Sch√§tzungen der Gemeinsamkeit, aber nur die  Faktorenanalyse kann die Einzigartigkeit (u2) jeder gemessenen Variable sch√§tzen. 

Die meisten Methodiker:innen empfehlen, dass die explorative Faktorenanalyse verwendet wird, um latente Konstrukte zu identifizieren. Fabrigar und Wegener (2012) empfahlen zum Beispiel Folgendes:

> *When the goal of research is to identify latent constructs for theory building or to create measurement instruments in which the researcher wishes to make the case that the resulting measurement instrument reflects a meaningful underlying construct, we argue that common factor analysis (EFA) procedures are usually preferable.* (Fabrigar und Wegener, 2012: 32)

In unserem Fall wenden wir eine explorative Faktorenanalyse an, da wir uns f√ºr die latente Variable *Vertrauen in gesellschaftliche Institutionen* interessieren. Hierf√ºr greifen wir auf das `psych`-Paket zur√ºck, welches die Funktion `fa` f√ºr eine Faktorenanalyse enth√§lt.

### Methode der Sch√§tzung

Nachdem wir die Faktorenanalyse (EFA) als bevorzugtes Modell festgelegt haben, m√ºssen wir noch die Methode zur Sch√§tzung (Extraktion) des Faktorenmodells ausw√§hlen. Konkret suchen wir ein mathematischen Verfahren, dass die Beziehungen zwischen den gemessenen Variablen und den Faktoren (d. h. die Regression der gemessenen Variablen auf die gemeinsamen Faktoren) m√∂glichst genau sch√§tzt.

Wir m√∂chten kurz anmerken, dass der mathematische Hintergrund an dieser Stelle des Kurses noch nicht so wichtig ist, da hier einige Grundlagen erst imd Kapitel 7 erkl√§rt werden. Trotzdem macht es unserer Einsch√§tzung nach Sinn die Begriffe bereits zu kennen und deren Vor- und Nachteile bennen zu k√∂nnen.

Es existieren eine ganze Reihe von unterschiedlichen Sch√§tzmethoden, von denen zwei Methoden am h√§ufigsten angewendet werden. (1) Die *ML-Sch√§tzung* (Maximum Liklelihood) beruht auf der Normalverteilung und ist entsprechend empfindlicher multivariater Normalit√§t und erfordert meistens einen gr√∂√üere Stichprobe (mehr F√§lle). (2) Die *PA* (wird auch als Hauptfaktoren, MINRES oder OLS bezeichnet) ist im Gegenzug dazu eine Methode der kleinsten Quadrate, welche keine Annahmen √ºber Verteilungen trifft. PA nutzt hier eine wiederholte Zwischensch√§tzung, welche eine bessere Sch√§tzung der Gemeinsamkeit erm√∂glicht und wiederholt diese bis eine zufriedenstellende L√∂sung erreicht ist. 

Die PA eignet sich als Methode der Sch√§tzung insbesondere dann, wenn der Zusammenhang zwischen den gemessenen Variablen und den Faktoren relativ schwach sind (‚â§.40), der Stichprobenumfang relativ klein ist (‚â§300), die multivariate Normalit√§t verletzt ist oder wenn die Anzahl der den gemessenen Variablen zugrunde liegenden Faktoren falsch spezifiziert ist. Im Gegensatz dazu ist eine ML-Sch√§tzung besser geeignet, wenn die Beziehungen zwischen Faktoren und Variablen stark sind (\>.40), der Stichprobenumfang gro√ü ist, multivariate Normalit√§t erreicht wird und die Anzahl der Faktoren korrekt angegeben ist.

Wir k√∂nnen f√ºr unser Beispiel weiterhin die Maximum-likelihood Faktorenanalyse aus dem `psych`-Paket mit der Funktion `fa` verwenden, da wir in unserem Fall die entsprechenden Voraussetzungen in Bezug auf den Stichprobenumfang, die St√§rke der Beziehung, sowie der Anzahl der Faktoren  erf√ºllen. F√ºr dieses Beispiel nutzen wir trotz der nicht perfekten Normalverteilung die ML Methode, alternativ k√∂nnten die PA Methode als robustere Variante nehmen.

### Anzahl der Faktoren

Wie bereits bei der ML-Sch√§tzung angedeutet, m√ºssen wir die Anzahl der Faktoren festlegen. Hierf√ºr m√ºssen wir die Anzahl der Faktoren f√ºr die weitere Analyse festlegen. Wir erreichen das indem wir mehrere Modelle sch√§tzen und somit R√ºckschl√ºsse auf ein optimales Modell mit der f√ºr uns passenden Anzahl an Faktoren ziehen. Vereinfacht k√∂nnen wir uns das Auswringen eines nassen Handtuchs vorstellen, bei der der erste Faktor die meiste Varianz extrahiert - ergo die gr√∂√üte Mene an Wasser - und die nachfolgenden Faktoren sukzessive kleinere Anteile der Varianz extrahieren. Auf diese Art und Weise k√∂nnen wir eine Sch√§tzung des optimalen Modells vornehmen.

Wir verwenden hierf√ºr die `nfactors`-Funktion, welche uns mehere Sch√§tzungen ausgibt.

```{r nfactors}
nfactors(allbus_vertrauen, rotate = "varimax", fm="mle")
```

Die minimalen durchschnittlichen Teilwerte (MAP), wird als die genauesten empirischen Sch√§tzungen f√ºr die Anzahl der beizubehaltenden Faktoren betrachtet. Der MAP Wert schl√§gt uns einen Faktor vor, entsprechend gehen wir im folgenden von einem Faktor bzw. einer lateten Variable aus.

### Rotation der Faktoren

Bei der Durchf√ºhrung der Faktorenanalyse werden sogenannte *Faktorladungen* ermittelt, die anzeigen, wie stark jede Variable mit den extrahierten Faktoren zusammenh√§ngt. W√§hrend des Analyseprozesses kann es vorkommen, dass die *Faktorladungen* rotiert werden, um eine eindeutigere und interpretierbarere Struktur der Faktoren zu erzielen. Die Rotation der *Faktorladungen* erm√∂glicht es, die Auspr√§gung der Faktoren auf weniger, aber st√§rker ausgepr√§gte Variablen zu konzentrieren, was die Interpretation und Verst√§ndlichkeit der Analyseergebnisse erleichtert. Es gibt verschiedene Rotationsmethoden, wie beispielsweise die Varimax- oder Quartimax-Rotation, die je nach Ziel der Faktorenanalyse angewendet werden k√∂nnen. Es existieren Dutzende von analytischen Rotationsmethoden, wobei Varimax die beliebteste orthogonale Rotationsmethode ist, w√§hrend Promax und Oblimin die beliebtesten schr√§gen Rotationsmethoden sind. Sowohl bei Promax als auch bei Oblimin k√∂nnen wir den Grad der Korrelation zwischen den Faktoren kontrollieren (√ºber die Parameter Kappa bzw. Delta).

Wichtig ist, dass sich die Interpretation der *Faktorladungen* zwischen orthogonalen und schr√§gen Rotationen unterscheiden. Bei orthogonalen L√∂sungen k√∂nnen die *Faktorladungen* als Korrelationen zwischen gemeinsamen Faktoren und gemessenen Variablen interpretiert werden. Diese Korrelationen reichen von -1,00 bis +1,00, und der Anteil der Varianz in einer gemessenen Variablen, der durch einen gemeinsamen Faktor beigetragen wurde, kann durch Quadrieren der Faktorladung berechnet werden. Im Gegensatz dazu ergeben sich bei schr√§gen L√∂sungen zwei verschiedene Arten von *Faktorladungen*: Struktur- und Musterkoeffizienten. Strukturkoeffizienten k√∂nnen auch als Korrelationen zwischen gemeinsamen Faktoren und den gemessenen Variablen interpretiert werden. Im Gegensatz dazu sind die Musterkoeffizienten keine einfachen Faktor-Variablen-Korrelationen mehr, sondern sie √§hneln standardisierten partiellen Regressionskoeffizienten. Das hei√üt, sie sind Korrelationen zwischen gemeinsamen Faktoren und gemessenen Variablen, nachdem der Einfluss aller anderen gemeinsamen Faktoren kontrolliert (herausgerechnet) wurde. Dementsprechend k√∂nnen Musterkoeffizienten den Wert von 1,00 √ºberschreiten und k√∂nnen nicht quadriert werden, um den Anteil der Varianz zu ermitteln, der eindeutig auf einen gemeinsamen Faktor zur√ºckzuf√ºhren ist. 

In unserem Fall greifen wir auf die etablierte Rotationsmethode `varimax` zur√ºck, welches wir entsprechend im R-Code spezifizieren. Zus√§tzlich geben wir unsere erwartete Anzahl an Faktoren an, welche wir zuvor bestimmt haben (in unserem Fall: 1).

```{r Modell der Faktorenanalyse}

# Wir f√ºhren die Faktorenanalyse aus und speichern die Ergebnisse in dem Objekt fit ab
fit =  fa(allbus_vertrauen, factors = 1, fm = "ml", rotation = "varimax")

# Anzeigen der Ergebnisse mit 2 Nachkommastellen und dem Ausblenden von Faktorladungen die kleiner als 0.3 sind

print(fit, digits = 2, cutoff = .3)
```

### Interpretation der Ergebnisse

Bei der Betrachtung des Outputs der explorativen Faktorenanalyse beginnen wir mit den *Faktorladungen*. *Faktorladungen* geben an, wie stark jede Variable mit den extrahierten Faktoren korreliert. Hohe positive Ladungen zeigen eine starke Beziehung zwischen der Variable und dem Faktor an, w√§hrend hohe negative Ladungen darauf hindeuten, dass die Variable invers mit dem Faktor zusammenh√§ngt. Variablen mit Ladungen nahe null haben wenig oder keine Beziehung zum jeweiligen Faktor. Durch die Betrachtung dieser Ladungen k√∂nnen wir die die Faktoren interpretieren und auch benennen. Auf diese Art und Weise k√∂nnen wir R√ºckschl√ºsse auf die zugrunde liegende latente Variable ziehen. In unserem Fall √ºbersteigen f√ºr alle Indikatoren die Faktorladungen √ºber den Wert 0.3, was auf einen relativ starken und damit f√ºr uns guten Zusammenhang mit dem Faktor bzw. der latenten Variable spricht.

Zus√§tzlich zur Interpretation der Faktorladungen ist es auch wichtig, die Uniquenes der Faktoren zu ber√ºcksichtigen. Diese zeigen an, wie viel Varianz in den Daten von jedem extrahierten Faktor erkl√§rt wird.  In anderen Worten sagt sie also aus, wie gut die Information der Variablen in den Faktoren insgesamt erhalten geblieben ist.

```{r Uniqueness}
print(fit$uniquenesses, digits = 2)
```

Wenn wir auf die Uniqueness der einzelnen Indikatoren blicken, wird relativ schnell klar, dass wir eine Reihe von Indikatoren mit hohen Uniqueness-Werten haben, deren Varianz zu gro√üen Teilen von der latenten Variable erkl√§ren wird und somit st√§rker als andere Indikatoren zu der latenten Variable "beitragen".

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse von Regressionsanalysen werden meistens in einer Tabelle dargestellt. F√ºr die Angabe im Text wird folgendes gebraucht:

‚úÖ die Werte des Kaiser-Meyer-Olkin Kritierums  (KMO)

‚úÖ das Ergebnis des Barlett-Tests

‚úÖ die Faktorladungen

‚úÖ die Uniqueness

‚úÖ die gew√§hlte Rotations-Methode


Das Format ist normalerweise:

> ***Beispiel:*** Zun√§chst wurde Faktorenanalyse der 15 gemessenen Indikatoren durchgef√ºhrt. Das Kaiser-Meyer-Olkin (KMO)-Ma√ü f√ºr die Stichprobenad√§quanz betrug 0,89. Dies deutet darauf hin, dass die Korrelationsmuster relativ kompakt sind und die Faktorenanalyse eindeutige und zuverl√§ssige Faktoren ergeben sollte. Der Bartlett-Test auf Sph√§rizit√§t war ebenfalls signifikant (œá2(105) = 33164.76, p < .001). Dies bedeutet, dass es einige Beziehungen zwischen den untersuchten Variablen gibt. Sowohl der KMO-Test als auch der Bartlett-Test best√§tigen, dass die Faktorenanalyse angemessen ist. 

>Die Faktoren werden rotiert, um eine einfache Struktur zu erhalten. In diesem Fall wurde die varimax Rotationsmethode verwendet. Nach sorgf√§ltiger Betrachtung der zusammenh√§ngenden Variablen in der Analyse wurden dann die Faktorbezeichnung vorgeschlagen und in Tabelle 1 dargestellt. Dabei handelt es sich um *Vertrauen in gesellschaftliche Institutionen*. F√ºr den Faktor wurden Faktorladungen erstellt (siehe Tabelle 1).
:::


## Danksagung und W√ºrdigung

Bei der Struktur und dem Inhalt dieser Seite haben mich die folgenden herausragenden Arbeiten inspieriert. Ich m√∂chte mich bei den Autor:innen f√ºr ihre Arbeit sehr bedanken!

* Daniela Keller [Link](https://www.youtube.com/watch?v=NFPGQcq1fO8) 
* Field, A., Miles, J., & Field, Z. (2012). Discovering statistics using R. 749-811
* Brown T. A. (2015). Confirmatory factor analysis for applied research (2nd ed.). New York, NY: Guilford Press. Watkins, M. W. (2018). Exploratory Factor Analysis: A Guide to Best Practice. Journal of Black Psychology, 44(3), 219--246. [Link](https://doi.org/10.1177/0095798418771807)

::: callout-note
## Literatur und Beispiele aus der Praxis

Wir empfehlen euch folgende Lehrb√ºcher, falls ihr weiterf√ºhrende Informationen braucht.

> üìñ Field, Z., Miles, J., & Field, A. (2012). Discovering statistics using R. Discovering statistics using r, 1-992. [Link](https://suche.suub.uni-bremen.de/peid=B68436977&LAN=DE&CID=7699632&index=L&Hitnr=1&dtyp=D&rtyp=a&Exemplar=1)

> üìñ Brown T. A. (2015). Confirmatory factor analysis for applied research (2nd ed.). New York, NY: Guilford Press. Watkins, M. W. (2018). Exploratory Factor Analysis: A Guide to Best Practice. Journal of Black Psychology, 44(3), 219--246. [Link](https://doi.org/10.1177/0095798418771807)

> üìñ Fabrigar, L. R., & Wegener, D. T. (2012). Exploratory factor analysis. Oxford University Press.

Hier findet ihr ein Beispiel aus der Forschungspraxis:

> üî¨ Koirala, B. P., Araghi, Y., Kroesen, M., Ghorbani, A., Hakvoort, R. A., & Herder, P. M. (2018). Trust, awareness, and independence: Insights from a socio-psychological factor analysis of citizen knowledge and participation in community energy systems. Energy research & social science, 38, 33-40. [Link](https://www.sciencedirect.com/science/article/pii/S2214629618300641)
:::
