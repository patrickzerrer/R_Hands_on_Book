---
title: "Zusammenh√§nge bei zwei Variablen mittels Korrelation und Regression"
author: "Stephanie Geise"
toc: true
number-sections: true
highlight-style: pygments
format:
  html:
    code-fold: false
    code-line-numbers: true
---

Das √úberpr√ºfen von Zusammenh√§ngen bei zwei Variablen

# Das √úberpr√ºfen von Zusammenh√§ngen bei zwei nominalskalierten Variablen

Pearson Chi-Quadrat

# Das √úberpr√ºfen von Zusammenh√§ngen bei zwei nominalskalierten Variablen

Rangkorrelation

# Das √úberpr√ºfen von Zusammenh√§ngen bei zwei intervalskalierten Variablen

## Korrelation

## Analyselogik, Ziel und Einsatzgebiete einer Regressionsanalyse

In diesem Notebook wird die **einfache lineare Regression** auf Grundlage der ESS-Daten vorgestellt. In der n√§chsten Sitzung gehen wir n√§her auf die Pr√ºfung der **Voraussetzungen einer Regressionsanalyse** ein und lernen die **multiple lineare Regression** kennen.

![Picture generated by Midjourney](Loffeskater_Correlation_is_not_causation_e993d16d-c1e3-42bc-a3eb-116ae864f87c.png)

### Anwendungsbereich der linearen Regression

Die einfache lineare Regressionsanalyse wird angewandt, wenn gepr√ºft werden soll, ob ein (als linear vermuteter) Zusammenhang zwischen zwei metrischen Variablen besteht. Sie wird daher auch als bivariate Regression bezeichnet.

Ziel ist es, die Beziehung zwischen einer abh√§ngigen Variable (auch erkl√§rte Variable, Regressand oder Prognosevariable genannt) und einer oder mehreren unabh√§ngigen Variablen (oft auch erkl√§rende Variable, Regressor oder Pr√§diktorvariable) zu analysieren, um Zusammenh√§nge quantitativ zu beschreiben und zu erkl√§ren und/oder Werte der abh√§ngigen Variable mit Hilfe der unabh√§ngige Variable (des Pr√§diktors) zu prognostizieren. Mit Hilfe der Regressionsanalyse k√∂nnen drei Arten von Fragestellungen untersucht werden: 1) Ursachenanalyse: Gibt es einen Zusammenhang zwischen der unabh√§ngigen und der abh√§ngigen Variable? Wie stark ist dieser? 2) Wirkungsanalyse: Wie ver√§ndert sich die abh√§ngige Variable bei einer √Ñnderung der unabh√§ngigen Variablen? 3) Prognose: K√∂nnen die Messwerte der abh√§ngigen Variable durch die Werte der unabh√§ngigen Variable vorhergesagt werden?

### Vorbereitung und Laden der Daten

Zun√§chst laden wir die Pakete des tidyverse. Weiterhin laden wir das Pakete broom um die normale Ausgabe der Funktion lm (f√ºr die Berechnung linearer Modelle) in ein etwas anschaulicheres Format umwandeln zu k√∂nnen. Au√üerdem laden wir das Paket performance, dass uns sp√§ter zus√§tzlich einige Indikatoren ausgibt.

Den Datensatz finet ihr [**hier**](https://ess-search.nsd.no/en/study/f8e11f55-0c14-4ab3-abde-96d3f14d3c76).

```{r Laden der notwendigen Pakete}

#Laden der notwendigen Pakete
#install.packages("lm.beta") 
#install.packages("broom") 
#install.packages("performance")
#install.packages("see")

library(tidyverse)
library(lm.beta)
library(broom) # hier stecken einige Befehle zur Bereinigung der Daten und der Modelloutputs drin
library(performance)
library(see)

#Daten laden und zum Datenobjekt "daten" zuweisen
daten <- read_rds("Datensatz/ESS8_vier_laender.rds")

#Visualisierungshintergrund der Grafiken in ggplot festlegen
theme_set(theme_minimal())

# Anzeige der p-Werte als Zahlen mit Nachkommastellen einstellen
options(scipen = 999) 

```

### Ziel der Analyse

Mit Hilfe der Regression wollen wir die Annahme pr√ºfen, dass das Alter (agea) der Befragten einen Einfluss auf die Internetnutzung (netustm, in Minuten) hat. Beides sind metrische Variablen und erf√ºllen damit die Voraussetzung, dass eine Regression gerechnet werden kann. (Achtung: auch kategorische Variablen k√∂nnen bei der Regressionsanalyse eingesetzt werden, sie m√ºssen dann aber durch Dummy-Coding passend gemacht werden).

### Data Management

Damit der Output etwas nachvollziehbarer wird, benenne ich die Variablen mit dem rename-Befehl zun√§chst einmal um. Dann nutze ich den drop_na-Befehl, um alle F√§llen mit fehlenden Werten zu entfernen (in der Klammer spezifiziere ich, auf welche Variablen sich der Befehl beziehen soll). Das alles weise ich einem neuen Datenobjekt zu: daten_mod

Schlie√ülich nutze ich den slice_sample-Befehl, um aus unseren 8432 F√§llen ein Zufallssample von n=100 F√§llen zu ziehen, weil mir das die visuelle Interpretation erleichtert (diesen Befehl k√∂nnten wir hier auch weglassen, dann bekommen wir unten aber sehr sehr viele Datenpunkt in unserem Streudiagramm - probieren Sie es mal aus!)

```{r Daten zum Zusammenhang von Alter und Internetnutzung alternativ vorbereiten}
daten_mod <- daten %>% 
  rename(alter = agea,
         internetnutzung = netustm) %>% 
  drop_na(c(alter, internetnutzung)) %>% 
slice_sample(n = 100) 
daten_mod
```

### Pr√ºfung der Voraussetzungen 1: Grafische Darstellung des Zusammenhangs der beiden Variablen, um die Annahme von Linearit√§t zu pr√ºfen

ACHTUNG! F√ºr die Regressionsanalyse m√ºssen noch weitere Voraussetzungen gepr√ºft werden (insb. Homoskedastizit√§t der Residuen; Unabh√§ngigkeit der Residuen; Normalverteilung der Residuen; keine Ausrei√üer in den Daten). An dieser Stelle klammern wir die anderen Voraussetzungspr√ºfungen aber vorerst aus, und kommen in der n√§chsten Sitzung darauf zur√ºck (das ist sonst zu viel auf einmal).

Zur visuellen Inspektion, ob der Zusammenhang zwischen unseren beiden Variablen linear ist, erstellen wir nun mit dem Befehl geom_point ein Punktdiagramm mit den Variablen Alter und Internetnutzung. Praktischerweise ist die Regressionsformel schon in ggplot integriert: Der Befehl geom_smooth erzeugt eine Trendlinie nach dem linear model (method = lm), die die Beziehung von y (=Internetznutzung) und x (=Alter) abbildet. Das Ergebnis ist eine Linie nach einer linearen Gleichung, die den Daten so eng wie m√∂glich folgt. Mit dem Befehl ggtitle legen wir dann noch in den Klammern den Titel der Grafik fest, und mit xlab und ylab erg√§nzen wir die Achsenbeschriftung.

```{r Zusammenhang von Alter und Internetnutzung plotten}
ggplot(daten_mod, aes(alter, internetnutzung)) + 
  geom_point() + 
  geom_smooth(method = lm, formula = "y ~ x") + 
  ggtitle("Zusammenhang der Variablen Alter und Internetnutzung") + 
  xlab("Alter") + ylab("t√§gliche Internetnutzung (Minuten)")
```

### Interpretation: Was sehen wir im Streudiagramm?

Die grafische Darstellung legt uns einen schwachen negativen (aber linearen!) Zusammenhang zwischen Alter und Internetnutzung nahe: mit zunehmendem Alter sinkt die Nutzungsdauer. Damit scheint eine wichtige Voraussetzung der Regressionsanalyse, dass der Zusammenhang an sich linear ist, erf√ºllt.

Nicht wundern: Weil wir oben ein Zufallssample gezogen haben, sieht die Grafik bei Ihnen allen etwas anders aus. Sie kann dadurch auch so ausfallen, dass der lineare Zusammenhang nicht (gut) sichtbar ist -- vor allem dann, wenn Ausrei√üer das Ergebnis massiv verzerren (z.B. wenn ein oder zwei √§ltere Nutzer mit \[unrealistisch?\] hoher Nutzungsdauer in ihrer Zufallstichprobe gelandet sind).

### Durchf√ºhrung der einfachen linearen Regression √ºber die Funktion lm

Ob diese Beobachtung auch statistisch belastbar ist, wollen wir jetzt mit der **einfachen linearen Regressionsanalyse** pr√ºfen. Dazu nutzen wir die Funktion lm(). Die Funktion lm steht f√ºr "linear model". In den Klammern benennen wir zun√§chst die abh√§ngige Variable (hier: Internetznutzung), dann kommt eine Tilde (d.h. "wird definiert durch") und der Bezug auf unsere unabh√§ngige Variable (hier: Alter). Die Schreibweise y \~ x ist die Formel-Schreibweise in R; in diesem Fall besagt sie, dass y (Internetnutzung) abh√§ngig von x (Alter) ist. Nach dem Komma folgt dann die Benennung des Datensatzes auf den die lm-Funktion angewendet werden soll.

Der Modelloutput von lm √§hnelt dem der schon behandelten Hypothesentests; enth√§lt aber noch weitere Eckdaten wie die Effektst√§rke, das Signifikanzniveau oder die Erkl√§rungsst√§rke des Modells.

### Einfache lineare Regression mit lm (=linear models)

```{r Empirisches Modell zum Zusammenhang Alter und Internetnutzung berechnen}
model <- lm(internetnutzung ~ alter, data = daten_mod) 
model
```

Da dieser Output sehr, sehr sparsam und f√ºr uns noch wenig aussagekr√§ftig ist, erg√§nzen wir ihn mit dem bekannten summary-Befehl, den wir auf unser Modell anwenden. Die dann erscheinende Ausgabe ist das "Herzst√ºck" unserer Regressionsanalyse (insbesondere, wenn sie um die standardisierten B-Koeffizienten erweitert wird - dazu kommen wir aber unten noch). Jetzt nutzen wir erst einmal die summary-Funktion, und wir erhalten im Output einen guten √úberblick √ºber unser Regressionsmodell:

```{r}
summary(model)
```

### Interpretation des Outputs: Was sehen wir in der Ausgabe?

Unter Call wird zun√§chst noch einmal das Regresssionsmodell beschrieben, das wir hier berechnet haben. In diesem versuchen wir auf Basis des Datensatzes "daten_mod" die abh√§ngige Variable "internetnutzung" durch die unabh√§ngige Variable "alter" zu erkl√§ren.

#### Residuen

Unter Resdiuen erhalten wir Informationen zur Verteilung der Residuen. Diese geben die Abweichung der beobachteten Werte von den durch das Regressionsmodell erwarteten Werten an.

Coefficients: \#### Intercept Das Intercept definiert den Schnittpunkt der Regressionsgeraden mit der y-Achse (theoretischer Wert f√ºr y, wenn x den Wert 0 annimmt).

#### Estimate

Die Estimates sind die unstandardisierte b-Werte. Das sind die Werte, die zur Vorhersage in die Regressionsgleichung eingetragen werden (k√∂nnten).

#### St. error

Hiermit wird der Standard-Fehler der unstandardisierten b-Werte ausgegeben.

#### t-value

Der t-value gibt den t-Wert des Modells an (Koeffizient / Standardfehler)

#### p-value

Der p-value ist f√ºr uns von besonderem Interesse - das ist der Signfikanzwert des Modells (unten mit Signfikanzsschwellen) bzw. des statistischen Zusammenhangs

#### R-squared

Auch beide R-Werte (R2, Adjusted R2) sind von zentraler Bedeutung f√ºr die Interpretation: R2 gibt uns die erkl√§rte Gesamtvarianz des Modells der abh√§ngigen Variable an, also die "Erkl√§rungskraft" der unabh√§ngigen Variable Alter auf die abh√§ngige Internetnutzung. Zur Interpretation bietet es sich an, R2 als Prozentwert mit 100 zu multiplizieren. Wir k√∂nnen hier dann daraus lesen, dass das Alter (14,7) Prozent der Varianz der Internetnutzung erkl√§rt. Das ist nicht super viel, aber auch nicht nichts. Wir k√∂nnen daraus aber auch ableiten, dass - neben dem Alter - noch andere Einflussfaktoren die Internetnutzung mitbestimmen m√ºssen. √úbrigens: Das R2 k√∂nnte theoretisch maximal den Wert 1 annehmen, dann h√§tten wir eine 100% Erkl√§rung der abh√§ngigen Variable durch die unabh√§ngige Variable (=\> das kommt aber in der Realit√§t aber fast nicht vor)

#### Adjusted R2

Wie der Name schon sagt bezeichnet Adjusted R2 die Anpassung des Modells, wobei f√ºr die Anzahl der aufgenommenen Variablen korrigiert wird ("Strafterm f√ºr viele aufgenommene Variablen"). Das Adjusted R2 ist daher immer schlechter als R2.

#### F-Statistik

Auch die F-Statistik ist wichtig: Sie gibt uns n√§mlich die Signfikanz des Gesamtmodells an (nicht einzelner Variablen wie bei R2!)

### Inhaltliche Interpretation: Was bedeutet das jetzt also alles?

Der Output zeigt uns: Das Alter hat einen negativen Einfluss auf die Internetnutzung. Je √§lter ein Nutzer ist, desto weniger nutzt er das Internet. Die Regressionsanalyse l√§sst dabei auch eine Quantifizierung dieses Zusammenhangs zu: Mit jeder Einheit, in der die unabh√§ngige Variable Alter steigt (hier: mit jedem Jahr Alter), nimmt die unabh√§ngige Variable Internetnutzung um (z.B. -4.642) Messeinheiten (hier: Minuten) ab. Dieser Zusammenhang ist mit p \> .05 statistisch signifikant.

::: callout-tip
## Wie gebe ich die Ergebnisse korrekt an?

Die Ergebnisse von Regressionsanalysen werden meistens in einer Tabelle dargestellt. F√ºr die Angabe im Text wird folgendes gebraucht:

‚úÖ den R2-Wert (das Bestimmungskoeffizient)

‚úÖ den F-Wert (auch als F-Statistik bezeichnet)

‚úÖ die Freiheitsgrade in Klammern

‚úÖ den p-Wert

Das Format ist normalerweise:

> ***Beispiel:*** Die UV beeinflusst die AV, *R^2^* = .24, *F*(1, 116) = 4.71, *p* = .003.
:::

### Vorhersage von Werten auf Basis des Modells

Da bei der Regression eine Funktion gesch√§tzt wird, k√∂nnen wir anhand der b-Werte und des Intercepts auch Vorhersagen f√ºr bestimmte F√§lle treffen. Das ist eine der **coolen Superkr√§fte** der Regressionsanalyse :) (Das gilt aber streng genommen nur, wenn das zu Grunde liegende Sample repr√§sentativ ist und das Modell sowie die Parameter signifikant sind).

Zur Prognose von erwarteten Werten der abh√§ngigen Variable (Internetnutzung) auf Basis von gegebenen Werten der unabh√§nigen Variable (Alter) kann man die predict.lm()-Funktion nutzen:

```{r Vorhersage des Modells f√ºr die t√§gliche Internetnutzung in Minuten bei Alter von 25 und 75}
predict.lm(model, data.frame(alter = 25))
predict.lm(model, data.frame(alter = 75))
```

### Inhaltliche Interpretation

Eine Person mit einem Alter von 25 Jahren weist laut Modell eine prognostizierte Internetnutzung von (306) Minuten auf. Eine Person mit einem Alter von 75 Jahren weist laut Modell eine prognostizierte Internetnutzung von (74) Minuten auf. (Nicht wundern, wenn Ihr Ergebnis leicht anders ausf√§llt: Der Wert variiert entsprechend der gezogenen Zufallsstichprobe.)

Das geht nat√ºrlich auch kombiniert in einem Befehl, dann m√ºssen wir aber mit c() einen combine-Befehl einf√ºgen:

```{r Vorhersage des Modells f√ºr die t√§gliche Internetnutzung in Minuten bei Alter 25 und 75}
predict.lm(model, data.frame(alter = c(25, 75)))
```

### Vorhersage und Residuen berechnen

Die Prognose-Leistung unseres Regressionsmodels k√∂nnen wir auch auf den gesamten Datensatz anwenden - dann bekommen wir f√ºr jeden Fall im Datensatz den prognostizierten Wert der abh√§ngigen Variable Internetkonsum ausgegeben. Dazu k√∂nnen wir den Befehl fitted nutzen. Der Fall Nummer 3 hat also laut Modell (!) einen Internetkonsum von (X) Minuten. (Nicht wundern, wenn Ihr Ergebnis leicht anders ausf√§llt: Der Wert variiert entsprechend der gezogenen Zufallsstichprobe.)

```{r Vorhersagewerte f√ºr jede Beobachtung anzeigen}
fitted(model) 
```

Nun haben wir aber im Rahmen unserer Befragung die Internetnutzung der Befragten aber ja schon erhoben. Wozu dient das dann? Ganz einfach: √úber die Ausgabe der prognostizierten Werte und der Residuen k√∂nnen wir sehen, wie hoch die Abweichung der Modellprognose ist, d.h. wie sehr die empirisch beobachteten Werte unserer F√§lle im Datensatz von den laut Modell erwarteten Werten abweichen. Um die Abweichung zu quantifizieren, nutzen wir die residuals.lm-Funktion:

```{r Residuen anzeigen}
residuals.lm(model)
```

### Inhaltliche Interpretation

F√ºr unseren Fall Nummer 3 betr√§gt die Abweichung der Prognose von der Beobachtung (121) Minuten. Das diese Abweichung sehr gro√ü ist, wundert uns aber nicht, denn wir wissen ja schon, dass wir eine gro√üe Spannweite haben und unser R2 mit 15 Prozent nicht besonders gro√ü ist.

### Vorhersage und Residuen grafisch darstellen

Um das grafisch gegen√ºberzustellen, speichern wir die obenen ausgegeben Daten zur Vorhersage (aus der predict-Funktion) und die Daten zu den Abweichungen von der Vorhersage (residuals-Funktion) jeweils als neue Variablen "vorhersage" und "residuen" ab.

```{r Berechnung der Vorhersagewerte und Residuen f√ºr zus√§tzliche Plots}
daten_mod$vorhersage <- predict(model) 
daten_mod$residuen <- residuals(model) 
```

Und dann machen wir eine fancy Grafik, die uns die Abweichung der prognostizierten Werte nach oben und nach unten visuell nachvollziehen l√§sst:

```{r Beobachtete und vorhergesagte Werte sowie Residuen gemeinsam plotten}
ggplot(daten_mod, aes(alter, internetnutzung)) + 
  geom_point(aes(color = residuen)) + # Festlegung der Farbmarkierung f√ºr die Residuen (Punkte sind tats√§chliche Werte, Linien die Residuen, Farbe gibt Gr√∂√üe der Abweichung an)
  scale_color_gradient2(low = "blue", mid = "white", high = "red") + # Festlegung der Farbe f√ºr die Residuen
  guides(color = "none") + # Unterdr√ºckt eine Legende an der Seite (ist obligatorisch)
  geom_point(aes(y = vorhersage), shape = 1) + # gibt die vorhergesagten Punkte auf der Regressionsgeraden aus
  geom_smooth(method = "lm", formula = "y ~ x", se = FALSE, linewidth = 0.5, color = "black") + # gibt die Regressionsgerade als Linie aus 
  geom_segment(aes(xend = alter, yend = vorhersage), alpha = .2) + # zeichnet die Linie vom Punkt zur Regressionsgeraden transparent ein 
  ggtitle("Vorhergesagte Werte und Residuen f√ºr Alter und Internetnutzung") + # Titel
  xlab("Alter") + ylab("t√§gliche Internetnutzung (Minuten)") # Achsen-Beschriftung
```

### Standardisierung der B-Koeffizienten ("beta-Koeffizienten")

Neben den normalen Regressionskoeffizienten b kann man auch die **standardisierten Koeffizienten beta** berechnen. Die standardisierten beta-Koeffizienten sind n√ºtzlich, weil sie die Skalierung der einzelnen Messwerte "herausrechnet", wodurch unterschiedlich skalierte Variablen vergleichbar werden.

Um uns die standardisierten beta-Koeffizienten ausgeben zu lassen, k√∂nnen wir auf das Paket lm.beta mit der gleichnamigen Funktion zur√ºckgreifen, die auf ein mit lm() erzeugtes Modell angewendet werden kann. Der nun folgende Befehl ist im Prinzip wie oben, nur in den Klammern erg√§nzt um die Funktion lm.beta(), die daf√ºr sorgt, dass wir im Output unten eine zus√§tzliche Spalte erhalten, in der die standardisierten B-Koeffizienten angezeigt werden. Diese sind als standardisierte "Regressionsgewichte" zu interpretieren - je h√∂her der Wert, desto st√§rker der erkl√§rende Beitrag der Variable.

Das ist nat√ºrlich vor allem dann spannend, wenn ich den Einfluss mehrerer Variablen vergleichen will. Dabei haben die standardisierten beta-Werte einen wichtigen Vorteil: Sollte man mehrere Pr√§diktoren in einem Modell haben, die aber auf unterschiedlichen Skalen gemessen wurden (z.B. 1x 5er und 1x 7er Skala), kann man ihren relativen Erkl√§rungsbeitrag untereinander vergleichen.

```{r}
summary(lm.beta(model)) 
```

### Zusatzfunktionen zur sch√∂neren Ergebnisdarstellung durch das Paket broom

```{r Modellzusammenfassung als data frame}
tidy(lm.beta(model))
```

```{r Weitere Modellstatistiken in einem Befehl berechnen}
glance(model)
```

```{r Rohdaten um Modellvorhersagen erweitern}
augment(model)
```

::: callout-note
## Literatur und Beispiele aus der Praxis

Wir empfehlen euch folgende Lehrb√ºcher, falls ihr weiterf√ºhrende Informationen braucht.

> üìñ Field, Z., Miles, J., & Field, A. (2012). Discovering statistics using R. Discovering statistics using r, 1-992. [Link](https://suche.suub.uni-bremen.de/peid=B68436977&LAN=DE&CID=7699632&index=L&Hitnr=1&dtyp=D&rtyp=a&Exemplar=1)

> üìñ D√∂ring, N., & Bortz, J. (2016). Forschungsmethoden und evaluation. Wiesbaden: Springerverlag. [Link](https://suche.suub.uni-bremen.de/peid=B77441304&LAN=DE&CID=7699632&index=L&Hitnr=1&dtyp=D&rtyp=a&Exemplar=1)

Hier findet ihr ein Beispiel aus der Forschungspraxis:

> üî¨ Weeks, B. E., & Holbert, R. L. (2013). Predicting dissemination of news content in social media: A focus on reception, friending, and partisanship. Journalism & Mass Communication Quarterly, 90(2), 212-232. [Link](https://journals.sagepub.com/doi/pdf/10.1177/1077699013482906?casa_token=ZaoVG0aHKusAAAAA:xsH-XzhmHjTPFafhnQkIQ5MaEvECLcI1WPrCn7uSaBCLQSgfgXHlSm2tk7ln9XZH-B_hrHHQTdqBVw)
:::
